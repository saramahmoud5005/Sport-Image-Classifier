{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTQb7oLxrJI_",
        "outputId": "cef9c528-fe28-4e0f-e2dc-11ddaf9ebc4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pyplot\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from random import shuffle\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import keras.layers as kl\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras import layers,regularizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Dense, UpSampling2D, BatchNormalization,Flatten, Dropout,  Add, Concatenate,AveragePooling2D, ZeroPadding2D,Activation\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import argparse\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfeq3mnouvxQ"
      },
      "source": [
        "<a name='1'></a>\n",
        "# Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IH8bDrxerVz2",
        "outputId": "6422e399-e411-4f22-f8bb-043a177af50c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YmFUkGduvPN"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/drive/MyDrive/NNproject/NNDataset.zip -d data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mN92OJpqvLQl"
      },
      "outputs": [],
      "source": [
        "dataset_path = '/content/data/Train' \n",
        "Test_path='/content/data/Test'\n",
        "saved_dataset_path='/content/drive/MyDrive/NNproject/train_data.npy'\n",
        "vgg16_weights_path='/content/drive/MyDrive/NNproject/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "resnet50_weights_path=\"/content/drive/MyDrive/NNproject/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
        "xception_weight_path=\"/content/drive/MyDrive/NNproject/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6VveHwPvR4T"
      },
      "outputs": [],
      "source": [
        "def create_label_in_binary(img_name):\n",
        "  word_label = img_name.split('_')[0]\n",
        "  if word_label == 'Basketball':\n",
        "    return word_label,np.array([1, 0, 0, 0, 0, 0])\n",
        "  if word_label == 'Football':\n",
        "    return word_label,np.array([0, 1, 0, 0, 0, 0])\n",
        "  if word_label == 'Rowing':\n",
        "    return word_label,np.array([0, 0, 1, 0, 0, 0])\n",
        "  if word_label == 'Swimming':\n",
        "    return word_label,np.array([0, 0, 0, 1, 0, 0])\n",
        "  if word_label == 'Tennis':\n",
        "    return word_label,np.array([0, 0, 0, 0, 1, 0])\n",
        "  if word_label == 'Yoga':\n",
        "    return word_label,np.array([0, 0, 0, 0, 0, 1])\n",
        "  else:\n",
        "    return 'unknwon',np.array([0, 0, 0, 0, 0, 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkIroRQ-vXs0"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 224\n",
        "from scipy import fft\n",
        "def create_dataset(path,IMAGE_SIZE=224):\n",
        "  dataset = []\n",
        "  dic={}\n",
        "  for img in tqdm(os.listdir(path)):\n",
        "    path = os.path.join(dataset_path, img)\n",
        "    img_data = cv2.imread(path) # BGR IMAGE\n",
        "    img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB)\n",
        "    img_data = cv2.resize(img_data, (IMAGE_SIZE, IMAGE_SIZE)) #new\n",
        "    img_data=fft.dct(np.array(img_data))\n",
        "    #print(img_data.shape)\n",
        "    \n",
        "    \n",
        "    \n",
        "    key,label=create_label_in_binary(img)\n",
        "    if key not in dic.keys():\n",
        "      dic[key]=[]\n",
        "    dic[key].append([np.array(img_data),label ])\n",
        "  return dic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wvlhcgj5vpKj",
        "outputId": "338d8f97-e631-4861-aa5d-fb5a853c5c12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1681/1681 [00:11<00:00, 143.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num of Basketball images 196\n",
            "num of Football images 400\n",
            "num of Tennis images 185\n",
            "num of Rowing images 202\n",
            "num of Yoga images 458\n",
            "num of Swimming images 240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "data=create_dataset(dataset_path)\n",
        "for key in data.keys():\n",
        "  print(\"num of \"+key+\" images \"+str(len(data[key])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zMJkxQq-inj"
      },
      "source": [
        "<a name='2'></a>\n",
        "# Train Validation split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5iqWeUF0E2c",
        "outputId": "bc93171c-1975-472c-cba2-34a966f3125e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  result = getattr(asarray(obj), method)(*args, **kwds)\n"
          ]
        }
      ],
      "source": [
        "#split data train 80%, validation 20% per each class\n",
        "train_data=[]\n",
        "validation_data=[]\n",
        "for key in data.keys():\n",
        "  train, validation = np.split(data[key], [int(len(data[key])*0.8)]) \n",
        "  train_data.extend(train)\n",
        "  validation_data.extend(validation)\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G14JpXjX4Qif",
        "outputId": "09c07cef-764c-48a3-fc3f-e957208467d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1343\n",
            "338\n"
          ]
        }
      ],
      "source": [
        "print(len(train_data))\n",
        "print(len(validation_data))\n",
        "shuffle(train_data)\n",
        "shuffle(validation_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGyPF1BB9zPH"
      },
      "outputs": [],
      "source": [
        "\n",
        "def resize_data(train_data,validation_data,IMAGE_SIZE):\n",
        "    X_train = np.array([cv2.resize(i[0], (IMAGE_SIZE, IMAGE_SIZE)) for i in train_data]).reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 3) # -1 means take any num of data. 3 means RGB\n",
        "    y_train = [i[1] for i in train_data]\n",
        "\n",
        "    X_validation = np.array([cv2.resize(i[0], (IMAGE_SIZE, IMAGE_SIZE)) for i in validation_data]).reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 3) # -1 means take any num of data. 3 means RGB\n",
        "    y_validation = [i[1] for i in validation_data]\n",
        "    return X_train,y_train,X_validation,y_validation\n",
        "X_train,y_train,X_validation,y_validation=resize_data(train_data,validation_data,224)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQxK8Lc3-6y7"
      },
      "outputs": [],
      "source": [
        "plt.title('Original image')\n",
        "plt.imshow(np.squeeze(X_train[0]))\n",
        "print(y_train[0])\n",
        "print(X_train[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz-5U4r4_Vha"
      },
      "source": [
        "<a name='3'></a>\n",
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJbVfqU3_NTP"
      },
      "outputs": [],
      "source": [
        "def img_normalized(img):\n",
        "  img=img/255.0\n",
        "  img-=0.5\n",
        "  img*=2\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jv8dWjGBQwKe"
      },
      "outputs": [],
      "source": [
        "def increasing_image_sharpening(img):\n",
        "  cv2.waitKey()\n",
        "  cv2.destroyAllWindows()\n",
        "  kernel = np.array([[0, -1, 0],\n",
        "                    [-1, 5,-1],\n",
        "                    [0, -1, 0]])\n",
        "  image_sharp = cv2.filter2D(src=img, ddepth=-1, kernel=kernel)\n",
        "  return image_sharp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDthgsjuQzD3"
      },
      "outputs": [],
      "source": [
        "def preprocessing(X):\n",
        "  newX=[]\n",
        "  for imgs in X:\n",
        "    img = increasing_image_sharpening(imgs)\n",
        "    img = img_normalized(img)\n",
        "    newX.append(img)\n",
        "  return newX "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4r4aQ2mQ9By"
      },
      "outputs": [],
      "source": [
        "def data_augmentation(img, img_label_in_binary):\n",
        "  X_augmented_images = []\n",
        "  y_augmented_images = []\n",
        "  \n",
        "  datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        fill_mode='nearest')\n",
        "  \n",
        "  img = np.expand_dims(img, 0)\n",
        "\n",
        "  num_of_augmented_images = 2\n",
        "  for i in range(num_of_augmented_images):\n",
        "    it = datagen.flow(img, batch_size=1)\n",
        "    batch = it.next()\n",
        "    aug_image = batch[0].astype('uint8')\n",
        "    X_augmented_images.append(np.array(aug_image))\n",
        "    y_augmented_images.append(img_label_in_binary)\n",
        "\n",
        "  return X_augmented_images, y_augmented_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxdKp_NJRYfY"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "X_augmented_images = []\n",
        "y_augmented_images = []\n",
        "\n",
        "for (img_data, img_label) in zip(X_train, y_train):\n",
        "  images, labels = data_augmentation(img_data, img_label)\n",
        "  images=preprocessing(images)\n",
        "  X_augmented_images.extend(images)\n",
        "  y_augmented_images.extend(labels)\n",
        "\n",
        "data={'image':X_augmented_images,'label':y_augmented_images}\n",
        "augmented_df=pd.DataFrame(data)\n",
        "augmented_df = pd.DataFrame(shuffle(augmented_df, random_state=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "vt-aIKBDR226",
        "outputId": "b5fd6397-b612-4c30-a6ff-3070d7862e1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 1]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.title('Preprocessed image')\n",
        "plt.imshow(augmented_df.iloc[0,0])\n",
        "print(augmented_df.iloc[0,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UmI1xKfXQKF"
      },
      "outputs": [],
      "source": [
        "nX_validation=preprocessing(X_validation)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgqyaF3IXFtF"
      },
      "source": [
        "<a name='4'></a>\n",
        "# Build CNN models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDCbWLTRYjWl"
      },
      "source": [
        "<a name='4-1'></a>\n",
        "> **VGG16**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MK_ZAE9uXBR8"
      },
      "outputs": [],
      "source": [
        "def VGG16():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\",name=\"input\"))\n",
        "    model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),name='vgg16'))\n",
        "    model.add(Flatten(name='flatten'))\n",
        "    #model.add(Dropout(0.5))\n",
        "    model.add(Dense(256, activation='relu', name='fc1'))\n",
        "    model.add(Dense(128, activation='relu', name='fc2'))\n",
        "    model.add(Dense(6, activation='softmax', name='output'))\n",
        "    return model\n",
        "def vgg_model():\n",
        "   model = VGG16()\n",
        "   \n",
        "   Vgg16 = Model(inputs=model.input, outputs=model.get_layer('vgg16').output)\n",
        "   Vgg16.load_weights(vgg16_weights_path)\n",
        "   for layer in Vgg16.layers: #to freeze top layers and tune nly the parameters of output layer\n",
        "    layer.trainable = False\n",
        "   #model.summary() \n",
        "   return model    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhX-M8yjYwFP"
      },
      "source": [
        "<a name='4-2'></a>\n",
        "> **googlenet_resnet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sFRPCI4X_7h"
      },
      "outputs": [],
      "source": [
        "CLASS_NUM = 6\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "IMAGE_SHAPE = (224, 224, 3)\n",
        "MODEL_NAME = 'googlenet_resnet'\n",
        "\n",
        "\n",
        "def inception(x, filters):\n",
        "    # 1x1\n",
        "    path1 = Conv2D(filters=filters[0], kernel_size=(1,1), strides=1, padding='same', activation='relu')(x)\n",
        "\n",
        "    # 1x1->3x3\n",
        "    path2 = Conv2D(filters=filters[1][0], kernel_size=(1,1), strides=1, padding='same', activation='relu')(x)\n",
        "    path2 = Conv2D(filters=filters[1][1], kernel_size=(3,3), strides=1, padding='same', activation='relu')(path2)\n",
        "    \n",
        "    # 1x1->5x5\n",
        "    path3 = Conv2D(filters=filters[2][0], kernel_size=(1,1), strides=1, padding='same', activation='relu')(x)\n",
        "    path3 = Conv2D(filters=filters[2][1], kernel_size=(5,5), strides=1, padding='same', activation='relu')(path3)\n",
        "\n",
        "    # 3x3->1x1\n",
        "    path4 = MaxPooling2D(pool_size=(3,3), strides=1, padding='same')(x)\n",
        "    path4 = Conv2D(filters=filters[3], kernel_size=(1,1), strides=1, padding='same', activation='relu')(path4)\n",
        "\n",
        "    return Concatenate(axis=-1)([path1,path2,path3,path4])\n",
        "\n",
        "\n",
        "def auxiliary(x, name=None):\n",
        "    layer = AveragePooling2D(pool_size=(5,5), strides=3, padding='valid')(x)\n",
        "    layer = Conv2D(filters=128, kernel_size=(1,1), strides=1, padding='same', activation='relu')(layer)\n",
        "    layer = Flatten()(layer)\n",
        "    layer = Dense(units=256, activation='relu')(layer)\n",
        "    layer = Dropout(0.4)(layer)\n",
        "    layer = Dense(units=CLASS_NUM, activation='softmax', name=name)(layer)\n",
        "    return layer\n",
        "\n",
        "\n",
        "def googlenet():\n",
        "    layer_in = Input(shape=IMAGE_SHAPE)\n",
        "    \n",
        "    # stage-1\n",
        "    layer = Conv2D(filters=64, kernel_size=(7,7), strides=2, padding='same', activation='relu')(layer_in)\n",
        "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
        "    layer = BatchNormalization()(layer)\n",
        "\n",
        "    # stage-2\n",
        "    layer = Conv2D(filters=64, kernel_size=(1,1), strides=1, padding='same', activation='relu')(layer)\n",
        "    layer = Conv2D(filters=192, kernel_size=(3,3), strides=1, padding='same', activation='relu')(layer)\n",
        "    layer = BatchNormalization()(layer)\n",
        "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
        "\n",
        "    # stage-3\n",
        "   \n",
        "    layer = inception(layer, [ 64,  (96,128), (16,32), 32]) #3a\n",
        "   \n",
        "\n",
        "    layer = inception(layer, [128, (128,192), (32,96), 64]) #3b\n",
        "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
        "    \n",
        "    # stage-4\n",
        "   \n",
        "    layer = inception(layer, [192,  (96,208),  (16,48),  64]) #4a\n",
        "    aux1  = auxiliary(layer, name='aux1')\n",
        "\n",
        "   \n",
        "    layer = inception(layer, [160, (112,224),  (24,64),  64]) #4b\n",
        "  \n",
        "\n",
        "    \n",
        "    layer = inception(layer, [128, (128,256),  (24,64),  64]) #4c\n",
        "   \n",
        "\n",
        "   \n",
        "    layer = inception(layer, [112, (144,288),  (32,64),  64]) #4d\n",
        "    aux2  = auxiliary(layer, name='aux2')\n",
        "\n",
        "  \n",
        "    layer = inception(layer, [256, (160,320), (32,128), 128]) #4e\n",
        "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
        "    \n",
        "    # stage-5\n",
        "   \n",
        "    layer = inception(layer, [256, (160,320), (32,128), 128]) #5a\n",
        "    \n",
        "    \n",
        " \n",
        "    layer = inception(layer, [384, (192,384), (48,128), 128]) #5b\n",
        "    layer = AveragePooling2D(pool_size=(7,7), strides=1, padding='valid')(layer)\n",
        "    \n",
        "    # stage-6\n",
        "    layer = Flatten()(layer)\n",
        "    layer = Dropout(0.4)(layer)\n",
        "    layer = Dense(units=256, activation='linear')(layer)\n",
        "    main = Dense(units=CLASS_NUM, activation='softmax', name='main')(layer)\n",
        "    \n",
        "    model = Model(inputs=layer_in, outputs=[main, aux1, aux2])\n",
        "    #model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjYQVgLDY9-j"
      },
      "source": [
        "<a name='4-3'></a>\n",
        "> **Resnet50**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZN_q6T0ZCQk"
      },
      "outputs": [],
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "   \n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    X_shortcut = X\n",
        "   \n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    X = Add()([X, X_shortcut])# SKIP Connection\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcSQze1taFn_"
      },
      "outputs": [],
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s=2):\n",
        "   \n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    X_shortcut = X\n",
        "\n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eSUJMQoaOSh"
      },
      "outputs": [],
      "source": [
        "def ResNet50(input_shape=(224, 224, 3)):\n",
        "\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    X = X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n",
        "    \n",
        "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
        "\n",
        "    return model\n",
        "def Pretrained_Resnet50():\n",
        "  base_model = ResNet50(input_shape=(224, 224, 3))\n",
        "  top_layer = base_model.output\n",
        "  top_layer = Flatten()(top_layer)\n",
        "  top_layer=Dense(256, activation='relu', name='fc1',kernel_initializer=glorot_uniform(seed=0))(top_layer)\n",
        "  #top_layer=Dropout(0.5)(top_layer)\n",
        "  top_layer=Dense(128, activation='relu', name='fc2',kernel_initializer=glorot_uniform(seed=0))(top_layer)\n",
        "  top_layer = Dense( 6,activation='softmax', name='fc3',kernel_initializer=glorot_uniform(seed=0))(top_layer)   \n",
        "\n",
        "  #load pretraind weights \n",
        "  base_model.load_weights(resnet50_weights_path) \n",
        "  model = Model(inputs=base_model.input, outputs=top_layer)\n",
        "\n",
        "  #frezzing layers of base model\n",
        "\n",
        "  for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        " \n",
        "  #model.summary()\n",
        "  return model  \n",
        "#Pretrained_Resnet50() "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Xception model\n",
        "\n"
      ],
      "metadata": {
        "id": "j-lTs3RK2ziS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input,Dense,Conv2D,Add\n",
        "from tensorflow.keras.layers import SeparableConv2D,ReLU\n",
        "from tensorflow.keras.layers import BatchNormalization,MaxPool2D\n",
        "from tensorflow.keras.layers import GlobalAvgPool2D\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "\n",
        "def xception():\n",
        "    input = Input(shape = (229,229,3))\n",
        "    x = Conv2D(32, (3, 3), strides=(2, 2), use_bias=False, name='block1_conv1')(input)\n",
        "    x = BatchNormalization(name='block1_conv1_bn')(x)\n",
        "    x = Activation('relu', name='block1_conv1_act')(x)\n",
        "    x = Conv2D(64, (3, 3), use_bias=False, name='block1_conv2')(x)\n",
        "    x = BatchNormalization(name='block1_conv2_bn')(x)\n",
        "    x = Activation('relu', name='block1_conv2_act')(x)\n",
        "\n",
        "    residual = Conv2D(128, (1, 1), strides=(2, 2),\n",
        "                      padding='same', use_bias=False)(x)\n",
        "    residual = BatchNormalization()(residual)\n",
        "\n",
        "    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False, name='block2_sepconv1')(x)\n",
        "    x = BatchNormalization(name='block2_sepconv1_bn')(x)\n",
        "    x = Activation('relu', name='block2_sepconv2_act')(x)\n",
        "    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False, name='block2_sepconv2')(x)\n",
        "    x = BatchNormalization(name='block2_sepconv2_bn')(x)\n",
        "\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block2_pool')(x)\n",
        "    x = layers.add([x, residual])\n",
        "\n",
        "    residual = Conv2D(256, (1, 1), strides=(2, 2),\n",
        "                      padding='same', use_bias=False)(x)\n",
        "    residual = BatchNormalization()(residual)\n",
        "\n",
        "    x = Activation('relu', name='block3_sepconv1_act')(x)\n",
        "    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False, name='block3_sepconv1')(x)\n",
        "    x = BatchNormalization(name='block3_sepconv1_bn')(x)\n",
        "    x = Activation('relu', name='block3_sepconv2_act')(x)\n",
        "    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False, name='block3_sepconv2')(x)\n",
        "    x = BatchNormalization(name='block3_sepconv2_bn')(x)\n",
        "\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block3_pool')(x)\n",
        "    x = layers.add([x, residual])\n",
        "\n",
        "    residual = Conv2D(728, (1, 1), strides=(2, 2),\n",
        "                      padding='same', use_bias=False)(x)\n",
        "    residual = BatchNormalization()(residual)\n",
        "\n",
        "    x = Activation('relu', name='block4_sepconv1_act')(x)\n",
        "    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name='block4_sepconv1')(x)\n",
        "    x = BatchNormalization(name='block4_sepconv1_bn')(x)\n",
        "    x = Activation('relu', name='block4_sepconv2_act')(x)\n",
        "    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name='block4_sepconv2')(x)\n",
        "    x = BatchNormalization(name='block4_sepconv2_bn')(x)\n",
        "\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block4_pool')(x)\n",
        "    x = layers.add([x, residual])\n",
        "\n",
        "    for i in range(8):\n",
        "        residual = x\n",
        "        prefix = 'block' + str(i + 5)\n",
        "\n",
        "        x = Activation('relu', name=prefix + '_sepconv1_act')(x)\n",
        "        x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv1')(x)\n",
        "        x = BatchNormalization(name=prefix + '_sepconv1_bn')(x)\n",
        "        x = Activation('relu', name=prefix + '_sepconv2_act')(x)\n",
        "        x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv2')(x)\n",
        "        x = BatchNormalization(name=prefix + '_sepconv2_bn')(x)\n",
        "        x = Activation('relu', name=prefix + '_sepconv3_act')(x)\n",
        "        x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv3')(x)\n",
        "        x = BatchNormalization(name=prefix + '_sepconv3_bn')(x)\n",
        "\n",
        "        x = layers.add([x, residual])\n",
        "\n",
        "    residual = Conv2D(1024, (1, 1), strides=(2, 2),\n",
        "                      padding='same', use_bias=False)(x)\n",
        "    residual = BatchNormalization()(residual)\n",
        "\n",
        "    x = Activation('relu', name='block13_sepconv1_act')(x)\n",
        "    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name='block13_sepconv1')(x)\n",
        "    x = BatchNormalization(name='block13_sepconv1_bn')(x)\n",
        "    x = Activation('relu', name='block13_sepconv2_act')(x)\n",
        "    x = SeparableConv2D(1024, (3, 3), padding='same', use_bias=False, name='block13_sepconv2')(x)\n",
        "    x = BatchNormalization(name='block13_sepconv2_bn')(x)\n",
        "\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block13_pool')(x)\n",
        "    x = layers.add([x, residual])\n",
        "\n",
        "    x = SeparableConv2D(1536, (3, 3), padding='same', use_bias=False, name='block14_sepconv1')(x)\n",
        "    x = BatchNormalization(name='block14_sepconv1_bn')(x)\n",
        "    x = Activation('relu', name='block14_sepconv1_act')(x)\n",
        "\n",
        "    x = SeparableConv2D(2048, (3, 3), padding='same', use_bias=False, name='block14_sepconv2')(x)\n",
        "    x = BatchNormalization(name='block14_sepconv2_bn')(x)\n",
        "    x = Activation('relu', name='block14_sepconv2_act')(x)\n",
        "    base_model = Model (inputs=input, outputs=x)\n",
        "    top_layer = base_model.output\n",
        "    # top_layer = GlobalAvgPool2D()(top_layer)\n",
        "    top_layer = Flatten()(top_layer)\n",
        "    top_layer = Dense(256, activation='relu', name='fc1')(top_layer)\n",
        "    #top_layer = Dropout(0.5)(top_layer)\n",
        "    top_layer = Dense(128, activation='relu', name='fc2')(top_layer)\n",
        "    top_layer = Dense (units = 6, activation = 'softmax')(top_layer)   \n",
        "\n",
        "  #load pretraind weights \n",
        "    base_model.load_weights(xception_weight_path) \n",
        "    model = Model(inputs=base_model.input, outputs=top_layer)\n",
        "     #frezzing layers of base model\n",
        "    for layer in base_model.layers:\n",
        "       layer.trainable = False\n",
        "   \n",
        "   \n",
        "    model.summary()\n",
        "    return model\n",
        "   \n",
        "# xception()    "
      ],
      "metadata": {
        "id": "HkxLaZSr_66j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZoN1kZGeT6k"
      },
      "source": [
        "<a name='5'></a>\n",
        "# Train CNN models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#best model\n",
        "X_train_xception,y_train_xception,X_valid_xception,y_valid_xception=resize_data(train_data,validation_data,229) \n",
        "X_train_xception=img_normalized(X_train_xception)\n",
        "X_valid_xception=img_normalized(X_valid_xception)\n",
        "\n",
        "X_train_xception = np.asarray(X_train_xception).astype(np.float32)\n",
        "y_train_xception = np.asarray(y_train_xception).astype(np.float32)\n",
        "X_valid_xception = np.asarray(X_valid_xception).astype(np.float32)\n",
        "y_valid_xception = np.asarray(y_valid_xception).astype(np.float32)\n",
        "\n",
        "Xception=xception()\n",
        "Xception.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=1e-3),metrics=[\"accuracy\"])\n",
        "mc = ModelCheckpoint('/content/drive/MyDrive/NNproject/xception.h5',monitor='val_accuracy', mode='max')\n",
        "Xception.fit(X_train_xception,  y_train_xception,validation_data=( X_valid_xception,  y_valid_xception),epochs=5,verbose=1,callbacks=[mc],shuffle=True )"
      ],
      "metadata": {
        "id": "XodGOWVGKb2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CZG6Y_UejSo"
      },
      "outputs": [],
      "source": [
        "def model_train(model,X_train,y_train,x_valid,y_valid,name_of_model,lr=1e-3):\n",
        "\n",
        "   if name_of_model ==\"googlenet_1\":\n",
        "     model.compile(loss='categorical_crossentropy', \n",
        "                  loss_weights={'main': 1.0, 'aux1': 0.3, 'aux2': 0.3},\n",
        "                  optimizer=Adam(learning_rate=lr),metrics = [\"accuracy\"])\n",
        "   else:\n",
        "      model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=lr),metrics=[\"accuracy\"])\n",
        "\n",
        "   es=EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=10)\n",
        "   mc = ModelCheckpoint('/content/drive/MyDrive/NNproject/'+name_of_model+'.h5', monitor='val_accuracy', mode='max', save_best_only=True)\n",
        "\n",
        "   fitModel = model.fit(X_train,  y_train,validation_data=( x_valid,  y_valid),epochs=100,verbose=1,callbacks=[es],shuffle=True )\n",
        "   return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LIf4RXu96IY"
      },
      "outputs": [],
      "source": [
        "#X_train,y_train,X_validation,y_validation\n",
        "x_train = np.asarray(X_train).astype(np.float32)\n",
        "Y_train = np.asarray(y_train).astype(np.float32)\n",
        "x_validation = np.asarray(X_validation).astype(np.float32)\n",
        "Y_validation = np.asarray(y_validation).astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecNxjVQ29vSa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52aefdc2-1cd8-48c0-b4eb-112c722825ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "42/42 [==============================] - 20s 174ms/step - loss: 183.2970 - accuracy: 0.3812 - val_loss: 7.3933 - val_accuracy: 0.5266\n",
            "Epoch 2/100\n",
            "42/42 [==============================] - 5s 118ms/step - loss: 2.3908 - accuracy: 0.6195 - val_loss: 1.4887 - val_accuracy: 0.5976\n",
            "Epoch 3/100\n",
            "42/42 [==============================] - 5s 118ms/step - loss: 1.0085 - accuracy: 0.6902 - val_loss: 0.9742 - val_accuracy: 0.6391\n",
            "Epoch 4/100\n",
            "42/42 [==============================] - 5s 126ms/step - loss: 0.6874 - accuracy: 0.7729 - val_loss: 0.8473 - val_accuracy: 0.7337\n",
            "Epoch 5/100\n",
            "42/42 [==============================] - 5s 121ms/step - loss: 0.5376 - accuracy: 0.8191 - val_loss: 0.8530 - val_accuracy: 0.7692\n",
            "Epoch 6/100\n",
            "42/42 [==============================] - 5s 124ms/step - loss: 0.5073 - accuracy: 0.8235 - val_loss: 1.3470 - val_accuracy: 0.7012\n",
            "Epoch 7/100\n",
            "42/42 [==============================] - 5s 121ms/step - loss: 0.5633 - accuracy: 0.8459 - val_loss: 1.1997 - val_accuracy: 0.6627\n",
            "Epoch 8/100\n",
            "42/42 [==============================] - 5s 122ms/step - loss: 0.4656 - accuracy: 0.8459 - val_loss: 0.9446 - val_accuracy: 0.7396\n",
            "Epoch 9/100\n",
            "42/42 [==============================] - 5s 123ms/step - loss: 0.4270 - accuracy: 0.8637 - val_loss: 1.0123 - val_accuracy: 0.7633\n",
            "Epoch 10/100\n",
            "42/42 [==============================] - 5s 122ms/step - loss: 0.2076 - accuracy: 0.9322 - val_loss: 1.0775 - val_accuracy: 0.7515\n",
            "Epoch 11/100\n",
            "42/42 [==============================] - 5s 124ms/step - loss: 0.4220 - accuracy: 0.8652 - val_loss: 0.8495 - val_accuracy: 0.7692\n",
            "Epoch 12/100\n",
            "42/42 [==============================] - 5s 125ms/step - loss: 0.1767 - accuracy: 0.9553 - val_loss: 0.7913 - val_accuracy: 0.7722\n",
            "Epoch 13/100\n",
            "42/42 [==============================] - 5s 126ms/step - loss: 0.1508 - accuracy: 0.9568 - val_loss: 0.8400 - val_accuracy: 0.7899\n",
            "Epoch 14/100\n",
            "42/42 [==============================] - 5s 126ms/step - loss: 0.0971 - accuracy: 0.9747 - val_loss: 0.7103 - val_accuracy: 0.8018\n",
            "Epoch 15/100\n",
            "42/42 [==============================] - 5s 127ms/step - loss: 0.0681 - accuracy: 0.9873 - val_loss: 0.6794 - val_accuracy: 0.8225\n",
            "Epoch 16/100\n",
            "42/42 [==============================] - 5s 127ms/step - loss: 0.0672 - accuracy: 0.9814 - val_loss: 1.0565 - val_accuracy: 0.7456\n",
            "Epoch 17/100\n",
            "42/42 [==============================] - 5s 129ms/step - loss: 0.1996 - accuracy: 0.9367 - val_loss: 1.3177 - val_accuracy: 0.7396\n",
            "Epoch 18/100\n",
            "42/42 [==============================] - 5s 129ms/step - loss: 0.6999 - accuracy: 0.8332 - val_loss: 1.5660 - val_accuracy: 0.7219\n",
            "Epoch 19/100\n",
            "42/42 [==============================] - 5s 130ms/step - loss: 0.2438 - accuracy: 0.9308 - val_loss: 0.9759 - val_accuracy: 0.7840\n",
            "Epoch 20/100\n",
            "42/42 [==============================] - 5s 130ms/step - loss: 0.3031 - accuracy: 0.9233 - val_loss: 1.2110 - val_accuracy: 0.7515\n",
            "Epoch 21/100\n",
            "42/42 [==============================] - 5s 130ms/step - loss: 0.1452 - accuracy: 0.9523 - val_loss: 1.0830 - val_accuracy: 0.7781\n",
            "Epoch 22/100\n",
            "42/42 [==============================] - 5s 128ms/step - loss: 0.1127 - accuracy: 0.9643 - val_loss: 0.8707 - val_accuracy: 0.7959\n",
            "Epoch 23/100\n",
            "42/42 [==============================] - 5s 128ms/step - loss: 0.0451 - accuracy: 0.9866 - val_loss: 1.0290 - val_accuracy: 0.8047\n",
            "Epoch 24/100\n",
            "42/42 [==============================] - 5s 127ms/step - loss: 0.1638 - accuracy: 0.9523 - val_loss: 1.1176 - val_accuracy: 0.7751\n",
            "Epoch 25/100\n",
            "42/42 [==============================] - 5s 127ms/step - loss: 0.2536 - accuracy: 0.9203 - val_loss: 1.2857 - val_accuracy: 0.7308\n",
            "Epoch 25: early stopping\n"
          ]
        }
      ],
      "source": [
        "resnet50=Pretrained_Resnet50()\n",
        "resnet50=model_train(resnet50,x_train,Y_train,x_validation,Y_validation,\"resnet50_1\",lr=1e-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1R0aFUxugalB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98d905a6-d98a-4001-f081-ef78b3bb1f1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 2.1332 - main_loss: 1.3883 - aux1_loss: 1.1975 - aux2_loss: 1.2855 - main_accuracy: 0.5134 - aux1_accuracy: 0.5618 - aux2_accuracy: 0.5208"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 31s 188ms/step - loss: 2.1332 - main_loss: 1.3883 - aux1_loss: 1.1975 - aux2_loss: 1.2855 - main_accuracy: 0.5134 - aux1_accuracy: 0.5618 - aux2_accuracy: 0.5208 - val_loss: 2.3198 - val_main_loss: 1.5059 - val_aux1_loss: 1.3267 - val_aux2_loss: 1.3866 - val_main_accuracy: 0.4320 - val_aux1_accuracy: 0.5680 - val_aux2_accuracy: 0.4941\n",
            "Epoch 2/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 1.5332 - main_loss: 0.9893 - aux1_loss: 0.8720 - aux2_loss: 0.9409 - main_accuracy: 0.6571 - aux1_accuracy: 0.6858 - aux2_accuracy: 0.6783"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 131ms/step - loss: 1.5332 - main_loss: 0.9893 - aux1_loss: 0.8720 - aux2_loss: 0.9409 - main_accuracy: 0.6571 - aux1_accuracy: 0.6858 - aux2_accuracy: 0.6783 - val_loss: 1.8621 - val_main_loss: 1.2122 - val_aux1_loss: 1.0210 - val_aux2_loss: 1.1454 - val_main_accuracy: 0.5917 - val_aux1_accuracy: 0.6775 - val_aux2_accuracy: 0.6154\n",
            "Epoch 3/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 1.4007 - main_loss: 0.9117 - aux1_loss: 0.7679 - aux2_loss: 0.8621 - main_accuracy: 0.6962 - aux1_accuracy: 0.7319 - aux2_accuracy: 0.7014"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 12s 142ms/step - loss: 1.4007 - main_loss: 0.9117 - aux1_loss: 0.7679 - aux2_loss: 0.8621 - main_accuracy: 0.6962 - aux1_accuracy: 0.7319 - aux2_accuracy: 0.7014 - val_loss: 1.2738 - val_main_loss: 0.8281 - val_aux1_loss: 0.7031 - val_aux2_loss: 0.7824 - val_main_accuracy: 0.7130 - val_aux1_accuracy: 0.7722 - val_aux2_accuracy: 0.7219\n",
            "Epoch 4/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 1.2003 - main_loss: 0.7754 - aux1_loss: 0.6762 - aux2_loss: 0.7399 - main_accuracy: 0.7360 - aux1_accuracy: 0.7666 - aux2_accuracy: 0.7394"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 131ms/step - loss: 1.2003 - main_loss: 0.7754 - aux1_loss: 0.6762 - aux2_loss: 0.7399 - main_accuracy: 0.7360 - aux1_accuracy: 0.7666 - aux2_accuracy: 0.7394 - val_loss: 1.1231 - val_main_loss: 0.7151 - val_aux1_loss: 0.6591 - val_aux2_loss: 0.7010 - val_main_accuracy: 0.7899 - val_aux1_accuracy: 0.7692 - val_aux2_accuracy: 0.7633\n",
            "Epoch 5/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 1.1078 - main_loss: 0.7282 - aux1_loss: 0.5969 - aux2_loss: 0.6682 - main_accuracy: 0.7606 - aux1_accuracy: 0.7982 - aux2_accuracy: 0.7759"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 1.1078 - main_loss: 0.7282 - aux1_loss: 0.5969 - aux2_loss: 0.6682 - main_accuracy: 0.7606 - aux1_accuracy: 0.7982 - aux2_accuracy: 0.7759 - val_loss: 1.1960 - val_main_loss: 0.7644 - val_aux1_loss: 0.6985 - val_aux2_loss: 0.7403 - val_main_accuracy: 0.7663 - val_aux1_accuracy: 0.7544 - val_aux2_accuracy: 0.7426\n",
            "Epoch 6/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.9818 - main_loss: 0.6437 - aux1_loss: 0.5244 - aux2_loss: 0.6024 - main_accuracy: 0.7822 - aux1_accuracy: 0.8168 - aux2_accuracy: 0.7867"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.9818 - main_loss: 0.6437 - aux1_loss: 0.5244 - aux2_loss: 0.6024 - main_accuracy: 0.7822 - aux1_accuracy: 0.8168 - aux2_accuracy: 0.7867 - val_loss: 1.1141 - val_main_loss: 0.6743 - val_aux1_loss: 0.7166 - val_aux2_loss: 0.7493 - val_main_accuracy: 0.7751 - val_aux1_accuracy: 0.7663 - val_aux2_accuracy: 0.7574\n",
            "Epoch 7/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.9090 - main_loss: 0.5956 - aux1_loss: 0.4908 - aux2_loss: 0.5538 - main_accuracy: 0.8086 - aux1_accuracy: 0.8321 - aux2_accuracy: 0.8120"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.9090 - main_loss: 0.5956 - aux1_loss: 0.4908 - aux2_loss: 0.5538 - main_accuracy: 0.8086 - aux1_accuracy: 0.8321 - aux2_accuracy: 0.8120 - val_loss: 0.9412 - val_main_loss: 0.6079 - val_aux1_loss: 0.5310 - val_aux2_loss: 0.5799 - val_main_accuracy: 0.8107 - val_aux1_accuracy: 0.8373 - val_aux2_accuracy: 0.8254\n",
            "Epoch 8/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.8490 - main_loss: 0.5612 - aux1_loss: 0.4404 - aux2_loss: 0.5188 - main_accuracy: 0.8157 - aux1_accuracy: 0.8488 - aux2_accuracy: 0.8273"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.8490 - main_loss: 0.5612 - aux1_loss: 0.4404 - aux2_loss: 0.5188 - main_accuracy: 0.8157 - aux1_accuracy: 0.8488 - aux2_accuracy: 0.8273 - val_loss: 0.9215 - val_main_loss: 0.6070 - val_aux1_loss: 0.5041 - val_aux2_loss: 0.5444 - val_main_accuracy: 0.7988 - val_aux1_accuracy: 0.8284 - val_aux2_accuracy: 0.8284\n",
            "Epoch 9/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.8157 - main_loss: 0.5505 - aux1_loss: 0.3897 - aux2_loss: 0.4946 - main_accuracy: 0.8179 - aux1_accuracy: 0.8641 - aux2_accuracy: 0.8328"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 130ms/step - loss: 0.8157 - main_loss: 0.5505 - aux1_loss: 0.3897 - aux2_loss: 0.4946 - main_accuracy: 0.8179 - aux1_accuracy: 0.8641 - aux2_accuracy: 0.8328 - val_loss: 1.1607 - val_main_loss: 0.7661 - val_aux1_loss: 0.6445 - val_aux2_loss: 0.6710 - val_main_accuracy: 0.7781 - val_aux1_accuracy: 0.7899 - val_aux2_accuracy: 0.7811\n",
            "Epoch 10/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.6993 - main_loss: 0.4668 - aux1_loss: 0.3602 - aux2_loss: 0.4146 - main_accuracy: 0.8399 - aux1_accuracy: 0.8697 - aux2_accuracy: 0.8567"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.6993 - main_loss: 0.4668 - aux1_loss: 0.3602 - aux2_loss: 0.4146 - main_accuracy: 0.8399 - aux1_accuracy: 0.8697 - aux2_accuracy: 0.8567 - val_loss: 0.9288 - val_main_loss: 0.6082 - val_aux1_loss: 0.5261 - val_aux2_loss: 0.5426 - val_main_accuracy: 0.8254 - val_aux1_accuracy: 0.8491 - val_aux2_accuracy: 0.8373\n",
            "Epoch 11/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.6698 - main_loss: 0.4513 - aux1_loss: 0.3314 - aux2_loss: 0.3970 - main_accuracy: 0.8511 - aux1_accuracy: 0.8868 - aux2_accuracy: 0.8693"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.6698 - main_loss: 0.4513 - aux1_loss: 0.3314 - aux2_loss: 0.3970 - main_accuracy: 0.8511 - aux1_accuracy: 0.8868 - aux2_accuracy: 0.8693 - val_loss: 0.9144 - val_main_loss: 0.5692 - val_aux1_loss: 0.5826 - val_aux2_loss: 0.5679 - val_main_accuracy: 0.8254 - val_aux1_accuracy: 0.8136 - val_aux2_accuracy: 0.8284\n",
            "Epoch 12/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.7080 - main_loss: 0.4746 - aux1_loss: 0.3454 - aux2_loss: 0.4325 - main_accuracy: 0.8317 - aux1_accuracy: 0.8820 - aux2_accuracy: 0.8470"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.7080 - main_loss: 0.4746 - aux1_loss: 0.3454 - aux2_loss: 0.4325 - main_accuracy: 0.8317 - aux1_accuracy: 0.8820 - aux2_accuracy: 0.8470 - val_loss: 0.9430 - val_main_loss: 0.5919 - val_aux1_loss: 0.5849 - val_aux2_loss: 0.5857 - val_main_accuracy: 0.8047 - val_aux1_accuracy: 0.8284 - val_aux2_accuracy: 0.8284\n",
            "Epoch 13/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.6252 - main_loss: 0.4224 - aux1_loss: 0.2992 - aux2_loss: 0.3765 - main_accuracy: 0.8582 - aux1_accuracy: 0.8961 - aux2_accuracy: 0.8790"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.6252 - main_loss: 0.4224 - aux1_loss: 0.2992 - aux2_loss: 0.3765 - main_accuracy: 0.8582 - aux1_accuracy: 0.8961 - aux2_accuracy: 0.8790 - val_loss: 1.0462 - val_main_loss: 0.6773 - val_aux1_loss: 0.5721 - val_aux2_loss: 0.6579 - val_main_accuracy: 0.7959 - val_aux1_accuracy: 0.8462 - val_aux2_accuracy: 0.8314\n",
            "Epoch 14/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.5509 - main_loss: 0.3742 - aux1_loss: 0.2671 - aux2_loss: 0.3220 - main_accuracy: 0.8730 - aux1_accuracy: 0.9088 - aux2_accuracy: 0.8909"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.5509 - main_loss: 0.3742 - aux1_loss: 0.2671 - aux2_loss: 0.3220 - main_accuracy: 0.8730 - aux1_accuracy: 0.9088 - aux2_accuracy: 0.8909 - val_loss: 0.9354 - val_main_loss: 0.5796 - val_aux1_loss: 0.5872 - val_aux2_loss: 0.5986 - val_main_accuracy: 0.8107 - val_aux1_accuracy: 0.8077 - val_aux2_accuracy: 0.8195\n",
            "Epoch 15/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.4626 - main_loss: 0.3149 - aux1_loss: 0.2166 - aux2_loss: 0.2755 - main_accuracy: 0.8909 - aux1_accuracy: 0.9278 - aux2_accuracy: 0.9088"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.4626 - main_loss: 0.3149 - aux1_loss: 0.2166 - aux2_loss: 0.2755 - main_accuracy: 0.8909 - aux1_accuracy: 0.9278 - aux2_accuracy: 0.9088 - val_loss: 0.9829 - val_main_loss: 0.6410 - val_aux1_loss: 0.5152 - val_aux2_loss: 0.6248 - val_main_accuracy: 0.8077 - val_aux1_accuracy: 0.8373 - val_aux2_accuracy: 0.8284\n",
            "Epoch 16/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.4314 - main_loss: 0.2947 - aux1_loss: 0.2040 - aux2_loss: 0.2516 - main_accuracy: 0.9002 - aux1_accuracy: 0.9356 - aux2_accuracy: 0.9170"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.4314 - main_loss: 0.2947 - aux1_loss: 0.2040 - aux2_loss: 0.2516 - main_accuracy: 0.9002 - aux1_accuracy: 0.9356 - aux2_accuracy: 0.9170 - val_loss: 1.1130 - val_main_loss: 0.6969 - val_aux1_loss: 0.7215 - val_aux2_loss: 0.6656 - val_main_accuracy: 0.8107 - val_aux1_accuracy: 0.8225 - val_aux2_accuracy: 0.8254\n",
            "Epoch 17/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.4568 - main_loss: 0.3158 - aux1_loss: 0.2016 - aux2_loss: 0.2683 - main_accuracy: 0.8984 - aux1_accuracy: 0.9289 - aux2_accuracy: 0.9144"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.4568 - main_loss: 0.3158 - aux1_loss: 0.2016 - aux2_loss: 0.2683 - main_accuracy: 0.8984 - aux1_accuracy: 0.9289 - aux2_accuracy: 0.9144 - val_loss: 1.0675 - val_main_loss: 0.6881 - val_aux1_loss: 0.5806 - val_aux2_loss: 0.6844 - val_main_accuracy: 0.8077 - val_aux1_accuracy: 0.8195 - val_aux2_accuracy: 0.8166\n",
            "Epoch 18/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.3457 - main_loss: 0.2456 - aux1_loss: 0.1308 - aux2_loss: 0.2029 - main_accuracy: 0.9207 - aux1_accuracy: 0.9538 - aux2_accuracy: 0.9293"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.3457 - main_loss: 0.2456 - aux1_loss: 0.1308 - aux2_loss: 0.2029 - main_accuracy: 0.9207 - aux1_accuracy: 0.9538 - aux2_accuracy: 0.9293 - val_loss: 0.7802 - val_main_loss: 0.4914 - val_aux1_loss: 0.5017 - val_aux2_loss: 0.4609 - val_main_accuracy: 0.8550 - val_aux1_accuracy: 0.8432 - val_aux2_accuracy: 0.8669\n",
            "Epoch 19/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.3584 - main_loss: 0.2456 - aux1_loss: 0.1598 - aux2_loss: 0.2163 - main_accuracy: 0.9203 - aux1_accuracy: 0.9464 - aux2_accuracy: 0.9293"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.3584 - main_loss: 0.2456 - aux1_loss: 0.1598 - aux2_loss: 0.2163 - main_accuracy: 0.9203 - aux1_accuracy: 0.9464 - aux2_accuracy: 0.9293 - val_loss: 1.4521 - val_main_loss: 0.9261 - val_aux1_loss: 0.8033 - val_aux2_loss: 0.9500 - val_main_accuracy: 0.7988 - val_aux1_accuracy: 0.8107 - val_aux2_accuracy: 0.8018\n",
            "Epoch 20/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.3551 - main_loss: 0.2491 - aux1_loss: 0.1421 - aux2_loss: 0.2115 - main_accuracy: 0.9207 - aux1_accuracy: 0.9509 - aux2_accuracy: 0.9311"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.3551 - main_loss: 0.2491 - aux1_loss: 0.1421 - aux2_loss: 0.2115 - main_accuracy: 0.9207 - aux1_accuracy: 0.9509 - aux2_accuracy: 0.9311 - val_loss: 0.8506 - val_main_loss: 0.5419 - val_aux1_loss: 0.4606 - val_aux2_loss: 0.5687 - val_main_accuracy: 0.8550 - val_aux1_accuracy: 0.8698 - val_aux2_accuracy: 0.8491\n",
            "Epoch 21/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.3241 - main_loss: 0.2301 - aux1_loss: 0.1244 - aux2_loss: 0.1888 - main_accuracy: 0.9233 - aux1_accuracy: 0.9613 - aux2_accuracy: 0.9345"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.3241 - main_loss: 0.2301 - aux1_loss: 0.1244 - aux2_loss: 0.1888 - main_accuracy: 0.9233 - aux1_accuracy: 0.9613 - aux2_accuracy: 0.9345 - val_loss: 1.2828 - val_main_loss: 0.7894 - val_aux1_loss: 0.8156 - val_aux2_loss: 0.8291 - val_main_accuracy: 0.8225 - val_aux1_accuracy: 0.8225 - val_aux2_accuracy: 0.8284\n",
            "Epoch 22/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.3805 - main_loss: 0.2628 - aux1_loss: 0.1599 - aux2_loss: 0.2325 - main_accuracy: 0.9214 - aux1_accuracy: 0.9483 - aux2_accuracy: 0.9330"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.3805 - main_loss: 0.2628 - aux1_loss: 0.1599 - aux2_loss: 0.2325 - main_accuracy: 0.9214 - aux1_accuracy: 0.9483 - aux2_accuracy: 0.9330 - val_loss: 0.8945 - val_main_loss: 0.5841 - val_aux1_loss: 0.4878 - val_aux2_loss: 0.5468 - val_main_accuracy: 0.8402 - val_aux1_accuracy: 0.8432 - val_aux2_accuracy: 0.8491\n",
            "Epoch 23/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.2249 - main_loss: 0.1609 - aux1_loss: 0.0846 - aux2_loss: 0.1287 - main_accuracy: 0.9471 - aux1_accuracy: 0.9698 - aux2_accuracy: 0.9602"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 129ms/step - loss: 0.2249 - main_loss: 0.1609 - aux1_loss: 0.0846 - aux2_loss: 0.1287 - main_accuracy: 0.9471 - aux1_accuracy: 0.9698 - aux2_accuracy: 0.9602 - val_loss: 1.3255 - val_main_loss: 0.8086 - val_aux1_loss: 0.8345 - val_aux2_loss: 0.8885 - val_main_accuracy: 0.8402 - val_aux1_accuracy: 0.8343 - val_aux2_accuracy: 0.8284\n",
            "Epoch 24/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.2649 - main_loss: 0.1880 - aux1_loss: 0.0994 - aux2_loss: 0.1571 - main_accuracy: 0.9393 - aux1_accuracy: 0.9676 - aux2_accuracy: 0.9464"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.2649 - main_loss: 0.1880 - aux1_loss: 0.0994 - aux2_loss: 0.1571 - main_accuracy: 0.9393 - aux1_accuracy: 0.9676 - aux2_accuracy: 0.9464 - val_loss: 0.8545 - val_main_loss: 0.5258 - val_aux1_loss: 0.5520 - val_aux2_loss: 0.5436 - val_main_accuracy: 0.8580 - val_aux1_accuracy: 0.8462 - val_aux2_accuracy: 0.8609\n",
            "Epoch 25/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.2174 - main_loss: 0.1533 - aux1_loss: 0.0885 - aux2_loss: 0.1250 - main_accuracy: 0.9512 - aux1_accuracy: 0.9713 - aux2_accuracy: 0.9553"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.2174 - main_loss: 0.1533 - aux1_loss: 0.0885 - aux2_loss: 0.1250 - main_accuracy: 0.9512 - aux1_accuracy: 0.9713 - aux2_accuracy: 0.9553 - val_loss: 1.0509 - val_main_loss: 0.6391 - val_aux1_loss: 0.6579 - val_aux2_loss: 0.7147 - val_main_accuracy: 0.8284 - val_aux1_accuracy: 0.8609 - val_aux2_accuracy: 0.8432\n",
            "Epoch 26/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.2500 - main_loss: 0.1783 - aux1_loss: 0.0977 - aux2_loss: 0.1412 - main_accuracy: 0.9419 - aux1_accuracy: 0.9684 - aux2_accuracy: 0.9520"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.2500 - main_loss: 0.1783 - aux1_loss: 0.0977 - aux2_loss: 0.1412 - main_accuracy: 0.9419 - aux1_accuracy: 0.9684 - aux2_accuracy: 0.9520 - val_loss: 1.0324 - val_main_loss: 0.6393 - val_aux1_loss: 0.7108 - val_aux2_loss: 0.5995 - val_main_accuracy: 0.8491 - val_aux1_accuracy: 0.8402 - val_aux2_accuracy: 0.8491\n",
            "Epoch 27/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.2036 - main_loss: 0.1431 - aux1_loss: 0.0845 - aux2_loss: 0.1171 - main_accuracy: 0.9557 - aux1_accuracy: 0.9713 - aux2_accuracy: 0.9617"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 129ms/step - loss: 0.2036 - main_loss: 0.1431 - aux1_loss: 0.0845 - aux2_loss: 0.1171 - main_accuracy: 0.9557 - aux1_accuracy: 0.9713 - aux2_accuracy: 0.9617 - val_loss: 1.1228 - val_main_loss: 0.7249 - val_aux1_loss: 0.6807 - val_aux2_loss: 0.6457 - val_main_accuracy: 0.8402 - val_aux1_accuracy: 0.8698 - val_aux2_accuracy: 0.8550\n",
            "Epoch 28/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.2099 - main_loss: 0.1444 - aux1_loss: 0.0916 - aux2_loss: 0.1266 - main_accuracy: 0.9561 - aux1_accuracy: 0.9728 - aux2_accuracy: 0.9613"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.2099 - main_loss: 0.1444 - aux1_loss: 0.0916 - aux2_loss: 0.1266 - main_accuracy: 0.9561 - aux1_accuracy: 0.9728 - aux2_accuracy: 0.9613 - val_loss: 1.0891 - val_main_loss: 0.6636 - val_aux1_loss: 0.7519 - val_aux2_loss: 0.6665 - val_main_accuracy: 0.8609 - val_aux1_accuracy: 0.8580 - val_aux2_accuracy: 0.8817\n",
            "Epoch 29/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.1800 - main_loss: 0.1280 - aux1_loss: 0.0665 - aux2_loss: 0.1067 - main_accuracy: 0.9542 - aux1_accuracy: 0.9780 - aux2_accuracy: 0.9672"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.1800 - main_loss: 0.1280 - aux1_loss: 0.0665 - aux2_loss: 0.1067 - main_accuracy: 0.9542 - aux1_accuracy: 0.9780 - aux2_accuracy: 0.9672 - val_loss: 1.0542 - val_main_loss: 0.6501 - val_aux1_loss: 0.7027 - val_aux2_loss: 0.6445 - val_main_accuracy: 0.8639 - val_aux1_accuracy: 0.8402 - val_aux2_accuracy: 0.8669\n",
            "Epoch 30/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.1223 - main_loss: 0.0864 - aux1_loss: 0.0482 - aux2_loss: 0.0716 - main_accuracy: 0.9717 - aux1_accuracy: 0.9829 - aux2_accuracy: 0.9762"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.1223 - main_loss: 0.0864 - aux1_loss: 0.0482 - aux2_loss: 0.0716 - main_accuracy: 0.9717 - aux1_accuracy: 0.9829 - aux2_accuracy: 0.9762 - val_loss: 1.3011 - val_main_loss: 0.8454 - val_aux1_loss: 0.7600 - val_aux2_loss: 0.7591 - val_main_accuracy: 0.8550 - val_aux1_accuracy: 0.8639 - val_aux2_accuracy: 0.8787\n",
            "Epoch 31/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.2319 - main_loss: 0.1674 - aux1_loss: 0.0814 - aux2_loss: 0.1334 - main_accuracy: 0.9434 - aux1_accuracy: 0.9732 - aux2_accuracy: 0.9572"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 127ms/step - loss: 0.2319 - main_loss: 0.1674 - aux1_loss: 0.0814 - aux2_loss: 0.1334 - main_accuracy: 0.9434 - aux1_accuracy: 0.9732 - aux2_accuracy: 0.9572 - val_loss: 1.1234 - val_main_loss: 0.6642 - val_aux1_loss: 0.7885 - val_aux2_loss: 0.7420 - val_main_accuracy: 0.8284 - val_aux1_accuracy: 0.8284 - val_aux2_accuracy: 0.8107\n",
            "Epoch 32/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.1613 - main_loss: 0.1124 - aux1_loss: 0.0675 - aux2_loss: 0.0957 - main_accuracy: 0.9687 - aux1_accuracy: 0.9810 - aux2_accuracy: 0.9751"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.1613 - main_loss: 0.1124 - aux1_loss: 0.0675 - aux2_loss: 0.0957 - main_accuracy: 0.9687 - aux1_accuracy: 0.9810 - aux2_accuracy: 0.9751 - val_loss: 0.9364 - val_main_loss: 0.5676 - val_aux1_loss: 0.6530 - val_aux2_loss: 0.5763 - val_main_accuracy: 0.8521 - val_aux1_accuracy: 0.8432 - val_aux2_accuracy: 0.8669\n",
            "Epoch 33/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0949 - main_loss: 0.0666 - aux1_loss: 0.0413 - aux2_loss: 0.0530 - main_accuracy: 0.9799 - aux1_accuracy: 0.9896 - aux2_accuracy: 0.9847"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0949 - main_loss: 0.0666 - aux1_loss: 0.0413 - aux2_loss: 0.0530 - main_accuracy: 0.9799 - aux1_accuracy: 0.9896 - aux2_accuracy: 0.9847 - val_loss: 2.3323 - val_main_loss: 1.4851 - val_aux1_loss: 1.3889 - val_aux2_loss: 1.4351 - val_main_accuracy: 0.7544 - val_aux1_accuracy: 0.7663 - val_aux2_accuracy: 0.7692\n",
            "Epoch 34/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.3012 - main_loss: 0.2043 - aux1_loss: 0.1393 - aux2_loss: 0.1838 - main_accuracy: 0.9360 - aux1_accuracy: 0.9576 - aux2_accuracy: 0.9486"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.3012 - main_loss: 0.2043 - aux1_loss: 0.1393 - aux2_loss: 0.1838 - main_accuracy: 0.9360 - aux1_accuracy: 0.9576 - aux2_accuracy: 0.9486 - val_loss: 1.2873 - val_main_loss: 0.7684 - val_aux1_loss: 0.9417 - val_aux2_loss: 0.7878 - val_main_accuracy: 0.8343 - val_aux1_accuracy: 0.8107 - val_aux2_accuracy: 0.8314\n",
            "Epoch 35/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.1157 - main_loss: 0.0816 - aux1_loss: 0.0474 - aux2_loss: 0.0662 - main_accuracy: 0.9721 - aux1_accuracy: 0.9847 - aux2_accuracy: 0.9792"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.1157 - main_loss: 0.0816 - aux1_loss: 0.0474 - aux2_loss: 0.0662 - main_accuracy: 0.9721 - aux1_accuracy: 0.9847 - aux2_accuracy: 0.9792 - val_loss: 1.5258 - val_main_loss: 1.0154 - val_aux1_loss: 0.8074 - val_aux2_loss: 0.8939 - val_main_accuracy: 0.8314 - val_aux1_accuracy: 0.8462 - val_aux2_accuracy: 0.8580\n",
            "Epoch 36/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.1729 - main_loss: 0.1295 - aux1_loss: 0.0525 - aux2_loss: 0.0923 - main_accuracy: 0.9609 - aux1_accuracy: 0.9836 - aux2_accuracy: 0.9728"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.1729 - main_loss: 0.1295 - aux1_loss: 0.0525 - aux2_loss: 0.0923 - main_accuracy: 0.9609 - aux1_accuracy: 0.9836 - aux2_accuracy: 0.9728 - val_loss: 1.1339 - val_main_loss: 0.7208 - val_aux1_loss: 0.6861 - val_aux2_loss: 0.6911 - val_main_accuracy: 0.8550 - val_aux1_accuracy: 0.8639 - val_aux2_accuracy: 0.8609\n",
            "Epoch 37/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.1594 - main_loss: 0.1109 - aux1_loss: 0.0768 - aux2_loss: 0.0849 - main_accuracy: 0.9669 - aux1_accuracy: 0.9799 - aux2_accuracy: 0.9728"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 130ms/step - loss: 0.1594 - main_loss: 0.1109 - aux1_loss: 0.0768 - aux2_loss: 0.0849 - main_accuracy: 0.9669 - aux1_accuracy: 0.9799 - aux2_accuracy: 0.9728 - val_loss: 2.0359 - val_main_loss: 1.3630 - val_aux1_loss: 0.8943 - val_aux2_loss: 1.3487 - val_main_accuracy: 0.7633 - val_aux1_accuracy: 0.8343 - val_aux2_accuracy: 0.7870\n",
            "Epoch 38/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.1593 - main_loss: 0.1159 - aux1_loss: 0.0573 - aux2_loss: 0.0871 - main_accuracy: 0.9628 - aux1_accuracy: 0.9836 - aux2_accuracy: 0.9724"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 130ms/step - loss: 0.1593 - main_loss: 0.1159 - aux1_loss: 0.0573 - aux2_loss: 0.0871 - main_accuracy: 0.9628 - aux1_accuracy: 0.9836 - aux2_accuracy: 0.9724 - val_loss: 1.0551 - val_main_loss: 0.6282 - val_aux1_loss: 0.7313 - val_aux2_loss: 0.6917 - val_main_accuracy: 0.8521 - val_aux1_accuracy: 0.8669 - val_aux2_accuracy: 0.8521\n",
            "Epoch 39/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.1519 - main_loss: 0.1087 - aux1_loss: 0.0594 - aux2_loss: 0.0848 - main_accuracy: 0.9650 - aux1_accuracy: 0.9821 - aux2_accuracy: 0.9747"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 127ms/step - loss: 0.1519 - main_loss: 0.1087 - aux1_loss: 0.0594 - aux2_loss: 0.0848 - main_accuracy: 0.9650 - aux1_accuracy: 0.9821 - aux2_accuracy: 0.9747 - val_loss: 0.9959 - val_main_loss: 0.6407 - val_aux1_loss: 0.5731 - val_aux2_loss: 0.6109 - val_main_accuracy: 0.8698 - val_aux1_accuracy: 0.8639 - val_aux2_accuracy: 0.8787\n",
            "Epoch 40/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0865 - main_loss: 0.0599 - aux1_loss: 0.0377 - aux2_loss: 0.0511 - main_accuracy: 0.9806 - aux1_accuracy: 0.9881 - aux2_accuracy: 0.9832"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0865 - main_loss: 0.0599 - aux1_loss: 0.0377 - aux2_loss: 0.0511 - main_accuracy: 0.9806 - aux1_accuracy: 0.9881 - aux2_accuracy: 0.9832 - val_loss: 1.0989 - val_main_loss: 0.6826 - val_aux1_loss: 0.6811 - val_aux2_loss: 0.7067 - val_main_accuracy: 0.8491 - val_aux1_accuracy: 0.8521 - val_aux2_accuracy: 0.8491\n",
            "Epoch 41/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.1269 - main_loss: 0.0859 - aux1_loss: 0.0687 - aux2_loss: 0.0678 - main_accuracy: 0.9736 - aux1_accuracy: 0.9795 - aux2_accuracy: 0.9799"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.1269 - main_loss: 0.0859 - aux1_loss: 0.0687 - aux2_loss: 0.0678 - main_accuracy: 0.9736 - aux1_accuracy: 0.9795 - aux2_accuracy: 0.9799 - val_loss: 2.6426 - val_main_loss: 1.8907 - val_aux1_loss: 1.0514 - val_aux2_loss: 1.4549 - val_main_accuracy: 0.7515 - val_aux1_accuracy: 0.8284 - val_aux2_accuracy: 0.7811\n",
            "Epoch 42/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0775 - main_loss: 0.0583 - aux1_loss: 0.0259 - aux2_loss: 0.0380 - main_accuracy: 0.9810 - aux1_accuracy: 0.9929 - aux2_accuracy: 0.9870"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 127ms/step - loss: 0.0775 - main_loss: 0.0583 - aux1_loss: 0.0259 - aux2_loss: 0.0380 - main_accuracy: 0.9810 - aux1_accuracy: 0.9929 - aux2_accuracy: 0.9870 - val_loss: 1.2289 - val_main_loss: 0.7411 - val_aux1_loss: 0.8255 - val_aux2_loss: 0.8005 - val_main_accuracy: 0.8402 - val_aux1_accuracy: 0.8698 - val_aux2_accuracy: 0.8373\n",
            "Epoch 43/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0722 - main_loss: 0.0500 - aux1_loss: 0.0289 - aux2_loss: 0.0451 - main_accuracy: 0.9873 - aux1_accuracy: 0.9907 - aux2_accuracy: 0.9862"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0722 - main_loss: 0.0500 - aux1_loss: 0.0289 - aux2_loss: 0.0451 - main_accuracy: 0.9873 - aux1_accuracy: 0.9907 - aux2_accuracy: 0.9862 - val_loss: 1.8827 - val_main_loss: 1.1235 - val_aux1_loss: 1.2450 - val_aux2_loss: 1.2858 - val_main_accuracy: 0.8314 - val_aux1_accuracy: 0.8550 - val_aux2_accuracy: 0.8432\n",
            "Epoch 44/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.1270 - main_loss: 0.0843 - aux1_loss: 0.0719 - aux2_loss: 0.0703 - main_accuracy: 0.9743 - aux1_accuracy: 0.9788 - aux2_accuracy: 0.9792"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.1270 - main_loss: 0.0843 - aux1_loss: 0.0719 - aux2_loss: 0.0703 - main_accuracy: 0.9743 - aux1_accuracy: 0.9788 - aux2_accuracy: 0.9792 - val_loss: 1.2975 - val_main_loss: 0.8335 - val_aux1_loss: 0.6712 - val_aux2_loss: 0.8755 - val_main_accuracy: 0.8728 - val_aux1_accuracy: 0.8905 - val_aux2_accuracy: 0.8609\n",
            "Epoch 45/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.1276 - main_loss: 0.0892 - aux1_loss: 0.0569 - aux2_loss: 0.0708 - main_accuracy: 0.9739 - aux1_accuracy: 0.9825 - aux2_accuracy: 0.9773"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 131ms/step - loss: 0.1276 - main_loss: 0.0892 - aux1_loss: 0.0569 - aux2_loss: 0.0708 - main_accuracy: 0.9739 - aux1_accuracy: 0.9825 - aux2_accuracy: 0.9773 - val_loss: 1.2981 - val_main_loss: 0.7824 - val_aux1_loss: 0.9100 - val_aux2_loss: 0.8089 - val_main_accuracy: 0.8402 - val_aux1_accuracy: 0.8521 - val_aux2_accuracy: 0.8373\n",
            "Epoch 46/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0807 - main_loss: 0.0606 - aux1_loss: 0.0344 - aux2_loss: 0.0326 - main_accuracy: 0.9765 - aux1_accuracy: 0.9881 - aux2_accuracy: 0.9885"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 127ms/step - loss: 0.0807 - main_loss: 0.0606 - aux1_loss: 0.0344 - aux2_loss: 0.0326 - main_accuracy: 0.9765 - aux1_accuracy: 0.9881 - aux2_accuracy: 0.9885 - val_loss: 1.2208 - val_main_loss: 0.7496 - val_aux1_loss: 0.7939 - val_aux2_loss: 0.7766 - val_main_accuracy: 0.8580 - val_aux1_accuracy: 0.8609 - val_aux2_accuracy: 0.8580\n",
            "Epoch 47/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0983 - main_loss: 0.0664 - aux1_loss: 0.0437 - aux2_loss: 0.0626 - main_accuracy: 0.9799 - aux1_accuracy: 0.9873 - aux2_accuracy: 0.9803"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0983 - main_loss: 0.0664 - aux1_loss: 0.0437 - aux2_loss: 0.0626 - main_accuracy: 0.9799 - aux1_accuracy: 0.9873 - aux2_accuracy: 0.9803 - val_loss: 1.6476 - val_main_loss: 0.9995 - val_aux1_loss: 1.0488 - val_aux2_loss: 1.1117 - val_main_accuracy: 0.8136 - val_aux1_accuracy: 0.8373 - val_aux2_accuracy: 0.8314\n",
            "Epoch 48/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.2051 - main_loss: 0.1428 - aux1_loss: 0.0962 - aux2_loss: 0.1114 - main_accuracy: 0.9617 - aux1_accuracy: 0.9788 - aux2_accuracy: 0.9698"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.2051 - main_loss: 0.1428 - aux1_loss: 0.0962 - aux2_loss: 0.1114 - main_accuracy: 0.9617 - aux1_accuracy: 0.9788 - aux2_accuracy: 0.9698 - val_loss: 1.2206 - val_main_loss: 0.7330 - val_aux1_loss: 0.7808 - val_aux2_loss: 0.8447 - val_main_accuracy: 0.8491 - val_aux1_accuracy: 0.8373 - val_aux2_accuracy: 0.8432\n",
            "Epoch 49/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0612 - main_loss: 0.0457 - aux1_loss: 0.0229 - aux2_loss: 0.0288 - main_accuracy: 0.9844 - aux1_accuracy: 0.9926 - aux2_accuracy: 0.9892"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0612 - main_loss: 0.0457 - aux1_loss: 0.0229 - aux2_loss: 0.0288 - main_accuracy: 0.9844 - aux1_accuracy: 0.9926 - aux2_accuracy: 0.9892 - val_loss: 1.1723 - val_main_loss: 0.7533 - val_aux1_loss: 0.6767 - val_aux2_loss: 0.7198 - val_main_accuracy: 0.8609 - val_aux1_accuracy: 0.8876 - val_aux2_accuracy: 0.8550\n",
            "Epoch 50/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0807 - main_loss: 0.0582 - aux1_loss: 0.0358 - aux2_loss: 0.0393 - main_accuracy: 0.9844 - aux1_accuracy: 0.9885 - aux2_accuracy: 0.9881"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0807 - main_loss: 0.0582 - aux1_loss: 0.0358 - aux2_loss: 0.0393 - main_accuracy: 0.9844 - aux1_accuracy: 0.9885 - aux2_accuracy: 0.9881 - val_loss: 1.3688 - val_main_loss: 0.8313 - val_aux1_loss: 0.9362 - val_aux2_loss: 0.8554 - val_main_accuracy: 0.8284 - val_aux1_accuracy: 0.8550 - val_aux2_accuracy: 0.8462\n",
            "Epoch 51/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0686 - main_loss: 0.0487 - aux1_loss: 0.0368 - aux2_loss: 0.0295 - main_accuracy: 0.9885 - aux1_accuracy: 0.9896 - aux2_accuracy: 0.9933"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0686 - main_loss: 0.0487 - aux1_loss: 0.0368 - aux2_loss: 0.0295 - main_accuracy: 0.9885 - aux1_accuracy: 0.9896 - aux2_accuracy: 0.9933 - val_loss: 1.2956 - val_main_loss: 0.7880 - val_aux1_loss: 0.7785 - val_aux2_loss: 0.9137 - val_main_accuracy: 0.8669 - val_aux1_accuracy: 0.8609 - val_aux2_accuracy: 0.8639\n",
            "Epoch 52/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0516 - main_loss: 0.0331 - aux1_loss: 0.0257 - aux2_loss: 0.0361 - main_accuracy: 0.9911 - aux1_accuracy: 0.9933 - aux2_accuracy: 0.9888"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0516 - main_loss: 0.0331 - aux1_loss: 0.0257 - aux2_loss: 0.0361 - main_accuracy: 0.9911 - aux1_accuracy: 0.9933 - aux2_accuracy: 0.9888 - val_loss: 2.2411 - val_main_loss: 1.4346 - val_aux1_loss: 1.2880 - val_aux2_loss: 1.4006 - val_main_accuracy: 0.8254 - val_aux1_accuracy: 0.8521 - val_aux2_accuracy: 0.8373\n",
            "Epoch 53/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.1542 - main_loss: 0.1101 - aux1_loss: 0.0678 - aux2_loss: 0.0793 - main_accuracy: 0.9717 - aux1_accuracy: 0.9762 - aux2_accuracy: 0.9747"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.1542 - main_loss: 0.1101 - aux1_loss: 0.0678 - aux2_loss: 0.0793 - main_accuracy: 0.9717 - aux1_accuracy: 0.9762 - aux2_accuracy: 0.9747 - val_loss: 1.1623 - val_main_loss: 0.6470 - val_aux1_loss: 0.8861 - val_aux2_loss: 0.8317 - val_main_accuracy: 0.8284 - val_aux1_accuracy: 0.8580 - val_aux2_accuracy: 0.8462\n",
            "Epoch 54/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0836 - main_loss: 0.0549 - aux1_loss: 0.0471 - aux2_loss: 0.0484 - main_accuracy: 0.9814 - aux1_accuracy: 0.9851 - aux2_accuracy: 0.9832"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 127ms/step - loss: 0.0836 - main_loss: 0.0549 - aux1_loss: 0.0471 - aux2_loss: 0.0484 - main_accuracy: 0.9814 - aux1_accuracy: 0.9851 - aux2_accuracy: 0.9832 - val_loss: 1.4219 - val_main_loss: 0.8731 - val_aux1_loss: 0.9176 - val_aux2_loss: 0.9118 - val_main_accuracy: 0.8609 - val_aux1_accuracy: 0.8817 - val_aux2_accuracy: 0.8669\n",
            "Epoch 55/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0682 - main_loss: 0.0485 - aux1_loss: 0.0294 - aux2_loss: 0.0362 - main_accuracy: 0.9862 - aux1_accuracy: 0.9903 - aux2_accuracy: 0.9907"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0682 - main_loss: 0.0485 - aux1_loss: 0.0294 - aux2_loss: 0.0362 - main_accuracy: 0.9862 - aux1_accuracy: 0.9903 - aux2_accuracy: 0.9907 - val_loss: 1.7901 - val_main_loss: 1.0828 - val_aux1_loss: 1.1792 - val_aux2_loss: 1.1784 - val_main_accuracy: 0.8550 - val_aux1_accuracy: 0.8373 - val_aux2_accuracy: 0.8550\n",
            "Epoch 56/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0654 - main_loss: 0.0511 - aux1_loss: 0.0207 - aux2_loss: 0.0269 - main_accuracy: 0.9896 - aux1_accuracy: 0.9940 - aux2_accuracy: 0.9903"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0654 - main_loss: 0.0511 - aux1_loss: 0.0207 - aux2_loss: 0.0269 - main_accuracy: 0.9896 - aux1_accuracy: 0.9940 - aux2_accuracy: 0.9903 - val_loss: 1.5529 - val_main_loss: 0.9187 - val_aux1_loss: 1.0533 - val_aux2_loss: 1.0606 - val_main_accuracy: 0.8402 - val_aux1_accuracy: 0.8462 - val_aux2_accuracy: 0.8462\n",
            "Epoch 57/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0330 - main_loss: 0.0235 - aux1_loss: 0.0167 - aux2_loss: 0.0151 - main_accuracy: 0.9914 - aux1_accuracy: 0.9952 - aux2_accuracy: 0.9952"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 127ms/step - loss: 0.0330 - main_loss: 0.0235 - aux1_loss: 0.0167 - aux2_loss: 0.0151 - main_accuracy: 0.9914 - aux1_accuracy: 0.9952 - aux2_accuracy: 0.9952 - val_loss: 1.3554 - val_main_loss: 0.8343 - val_aux1_loss: 0.8703 - val_aux2_loss: 0.8670 - val_main_accuracy: 0.8639 - val_aux1_accuracy: 0.8846 - val_aux2_accuracy: 0.8639\n",
            "Epoch 58/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0482 - main_loss: 0.0312 - aux1_loss: 0.0342 - aux2_loss: 0.0224 - main_accuracy: 0.9926 - aux1_accuracy: 0.9922 - aux2_accuracy: 0.9944"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0482 - main_loss: 0.0312 - aux1_loss: 0.0342 - aux2_loss: 0.0224 - main_accuracy: 0.9926 - aux1_accuracy: 0.9922 - aux2_accuracy: 0.9944 - val_loss: 1.3373 - val_main_loss: 0.7077 - val_aux1_loss: 1.2328 - val_aux2_loss: 0.8659 - val_main_accuracy: 0.8669 - val_aux1_accuracy: 0.8550 - val_aux2_accuracy: 0.8639\n",
            "Epoch 59/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0841 - main_loss: 0.0576 - aux1_loss: 0.0383 - aux2_loss: 0.0500 - main_accuracy: 0.9844 - aux1_accuracy: 0.9870 - aux2_accuracy: 0.9862"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0841 - main_loss: 0.0576 - aux1_loss: 0.0383 - aux2_loss: 0.0500 - main_accuracy: 0.9844 - aux1_accuracy: 0.9870 - aux2_accuracy: 0.9862 - val_loss: 1.4405 - val_main_loss: 0.8546 - val_aux1_loss: 1.0053 - val_aux2_loss: 0.9480 - val_main_accuracy: 0.8373 - val_aux1_accuracy: 0.8609 - val_aux2_accuracy: 0.8402\n",
            "Epoch 60/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.1791 - main_loss: 0.1214 - aux1_loss: 0.0778 - aux2_loss: 0.1143 - main_accuracy: 0.9669 - aux1_accuracy: 0.9777 - aux2_accuracy: 0.9713"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.1791 - main_loss: 0.1214 - aux1_loss: 0.0778 - aux2_loss: 0.1143 - main_accuracy: 0.9669 - aux1_accuracy: 0.9777 - aux2_accuracy: 0.9713 - val_loss: 1.4185 - val_main_loss: 0.8274 - val_aux1_loss: 1.0851 - val_aux2_loss: 0.8851 - val_main_accuracy: 0.8669 - val_aux1_accuracy: 0.8550 - val_aux2_accuracy: 0.8462\n",
            "Epoch 61/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0778 - main_loss: 0.0539 - aux1_loss: 0.0338 - aux2_loss: 0.0461 - main_accuracy: 0.9859 - aux1_accuracy: 0.9922 - aux2_accuracy: 0.9899"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 127ms/step - loss: 0.0778 - main_loss: 0.0539 - aux1_loss: 0.0338 - aux2_loss: 0.0461 - main_accuracy: 0.9859 - aux1_accuracy: 0.9922 - aux2_accuracy: 0.9899 - val_loss: 1.5371 - val_main_loss: 0.9752 - val_aux1_loss: 1.0157 - val_aux2_loss: 0.8573 - val_main_accuracy: 0.8521 - val_aux1_accuracy: 0.8846 - val_aux2_accuracy: 0.8757\n",
            "Epoch 62/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.1483 - main_loss: 0.1035 - aux1_loss: 0.0695 - aux2_loss: 0.0797 - main_accuracy: 0.9713 - aux1_accuracy: 0.9806 - aux2_accuracy: 0.9758"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 129ms/step - loss: 0.1483 - main_loss: 0.1035 - aux1_loss: 0.0695 - aux2_loss: 0.0797 - main_accuracy: 0.9713 - aux1_accuracy: 0.9806 - aux2_accuracy: 0.9758 - val_loss: 1.1287 - val_main_loss: 0.6869 - val_aux1_loss: 0.7722 - val_aux2_loss: 0.7006 - val_main_accuracy: 0.8491 - val_aux1_accuracy: 0.8728 - val_aux2_accuracy: 0.8757\n",
            "Epoch 63/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.1304 - main_loss: 0.0852 - aux1_loss: 0.0800 - aux2_loss: 0.0708 - main_accuracy: 0.9810 - aux1_accuracy: 0.9803 - aux2_accuracy: 0.9855"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.1304 - main_loss: 0.0852 - aux1_loss: 0.0800 - aux2_loss: 0.0708 - main_accuracy: 0.9810 - aux1_accuracy: 0.9803 - aux2_accuracy: 0.9855 - val_loss: 1.6346 - val_main_loss: 0.9874 - val_aux1_loss: 1.0799 - val_aux2_loss: 1.0775 - val_main_accuracy: 0.8284 - val_aux1_accuracy: 0.8491 - val_aux2_accuracy: 0.8432\n",
            "Epoch 64/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0333 - main_loss: 0.0230 - aux1_loss: 0.0207 - aux2_loss: 0.0138 - main_accuracy: 0.9948 - aux1_accuracy: 0.9929 - aux2_accuracy: 0.9955"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0333 - main_loss: 0.0230 - aux1_loss: 0.0207 - aux2_loss: 0.0138 - main_accuracy: 0.9948 - aux1_accuracy: 0.9929 - aux2_accuracy: 0.9955 - val_loss: 1.2194 - val_main_loss: 0.6842 - val_aux1_loss: 0.9845 - val_aux2_loss: 0.7994 - val_main_accuracy: 0.8639 - val_aux1_accuracy: 0.8580 - val_aux2_accuracy: 0.8728\n",
            "Epoch 65/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0850 - main_loss: 0.0621 - aux1_loss: 0.0342 - aux2_loss: 0.0424 - main_accuracy: 0.9855 - aux1_accuracy: 0.9911 - aux2_accuracy: 0.9914"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0850 - main_loss: 0.0621 - aux1_loss: 0.0342 - aux2_loss: 0.0424 - main_accuracy: 0.9855 - aux1_accuracy: 0.9911 - aux2_accuracy: 0.9914 - val_loss: 1.4838 - val_main_loss: 0.8549 - val_aux1_loss: 1.1241 - val_aux2_loss: 0.9720 - val_main_accuracy: 0.8373 - val_aux1_accuracy: 0.8373 - val_aux2_accuracy: 0.8343\n",
            "Epoch 66/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0868 - main_loss: 0.0601 - aux1_loss: 0.0328 - aux2_loss: 0.0560 - main_accuracy: 0.9851 - aux1_accuracy: 0.9914 - aux2_accuracy: 0.9859"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0868 - main_loss: 0.0601 - aux1_loss: 0.0328 - aux2_loss: 0.0560 - main_accuracy: 0.9851 - aux1_accuracy: 0.9914 - aux2_accuracy: 0.9859 - val_loss: 1.6221 - val_main_loss: 0.9935 - val_aux1_loss: 1.0705 - val_aux2_loss: 1.0248 - val_main_accuracy: 0.8373 - val_aux1_accuracy: 0.8669 - val_aux2_accuracy: 0.8521\n",
            "Epoch 67/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0726 - main_loss: 0.0538 - aux1_loss: 0.0277 - aux2_loss: 0.0352 - main_accuracy: 0.9836 - aux1_accuracy: 0.9914 - aux2_accuracy: 0.9899"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0726 - main_loss: 0.0538 - aux1_loss: 0.0277 - aux2_loss: 0.0352 - main_accuracy: 0.9836 - aux1_accuracy: 0.9914 - aux2_accuracy: 0.9899 - val_loss: 1.3650 - val_main_loss: 0.7705 - val_aux1_loss: 1.0792 - val_aux2_loss: 0.9024 - val_main_accuracy: 0.8609 - val_aux1_accuracy: 0.8728 - val_aux2_accuracy: 0.8698\n",
            "Epoch 68/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0210 - main_loss: 0.0118 - aux1_loss: 0.0189 - aux2_loss: 0.0115 - main_accuracy: 0.9970 - aux1_accuracy: 0.9948 - aux2_accuracy: 0.9978"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0210 - main_loss: 0.0118 - aux1_loss: 0.0189 - aux2_loss: 0.0115 - main_accuracy: 0.9970 - aux1_accuracy: 0.9948 - aux2_accuracy: 0.9978 - val_loss: 1.4255 - val_main_loss: 0.8610 - val_aux1_loss: 0.9439 - val_aux2_loss: 0.9378 - val_main_accuracy: 0.8580 - val_aux1_accuracy: 0.8787 - val_aux2_accuracy: 0.8580\n",
            "Epoch 69/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0474 - main_loss: 0.0349 - aux1_loss: 0.0181 - aux2_loss: 0.0237 - main_accuracy: 0.9870 - aux1_accuracy: 0.9948 - aux2_accuracy: 0.9922"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 130ms/step - loss: 0.0474 - main_loss: 0.0349 - aux1_loss: 0.0181 - aux2_loss: 0.0237 - main_accuracy: 0.9870 - aux1_accuracy: 0.9948 - aux2_accuracy: 0.9922 - val_loss: 1.7041 - val_main_loss: 1.0749 - val_aux1_loss: 1.0375 - val_aux2_loss: 1.0596 - val_main_accuracy: 0.8402 - val_aux1_accuracy: 0.8698 - val_aux2_accuracy: 0.8432\n",
            "Epoch 70/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.1506 - main_loss: 0.1060 - aux1_loss: 0.0695 - aux2_loss: 0.0794 - main_accuracy: 0.9728 - aux1_accuracy: 0.9806 - aux2_accuracy: 0.9780"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.1506 - main_loss: 0.1060 - aux1_loss: 0.0695 - aux2_loss: 0.0794 - main_accuracy: 0.9728 - aux1_accuracy: 0.9806 - aux2_accuracy: 0.9780 - val_loss: 1.2483 - val_main_loss: 0.6870 - val_aux1_loss: 1.0726 - val_aux2_loss: 0.7983 - val_main_accuracy: 0.8639 - val_aux1_accuracy: 0.8491 - val_aux2_accuracy: 0.8669\n",
            "Epoch 71/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0513 - main_loss: 0.0343 - aux1_loss: 0.0360 - aux2_loss: 0.0204 - main_accuracy: 0.9896 - aux1_accuracy: 0.9888 - aux2_accuracy: 0.9933"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0513 - main_loss: 0.0343 - aux1_loss: 0.0360 - aux2_loss: 0.0204 - main_accuracy: 0.9896 - aux1_accuracy: 0.9888 - aux2_accuracy: 0.9933 - val_loss: 1.5517 - val_main_loss: 0.8900 - val_aux1_loss: 1.0527 - val_aux2_loss: 1.1531 - val_main_accuracy: 0.8698 - val_aux1_accuracy: 0.8550 - val_aux2_accuracy: 0.8521\n",
            "Epoch 72/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0831 - main_loss: 0.0616 - aux1_loss: 0.0262 - aux2_loss: 0.0453 - main_accuracy: 0.9862 - aux1_accuracy: 0.9918 - aux2_accuracy: 0.9888"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 127ms/step - loss: 0.0831 - main_loss: 0.0616 - aux1_loss: 0.0262 - aux2_loss: 0.0453 - main_accuracy: 0.9862 - aux1_accuracy: 0.9918 - aux2_accuracy: 0.9888 - val_loss: 1.2140 - val_main_loss: 0.7180 - val_aux1_loss: 0.8199 - val_aux2_loss: 0.8335 - val_main_accuracy: 0.8550 - val_aux1_accuracy: 0.8728 - val_aux2_accuracy: 0.8609\n",
            "Epoch 73/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0377 - main_loss: 0.0230 - aux1_loss: 0.0284 - aux2_loss: 0.0209 - main_accuracy: 0.9926 - aux1_accuracy: 0.9918 - aux2_accuracy: 0.9914"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0377 - main_loss: 0.0230 - aux1_loss: 0.0284 - aux2_loss: 0.0209 - main_accuracy: 0.9926 - aux1_accuracy: 0.9918 - aux2_accuracy: 0.9914 - val_loss: 2.1102 - val_main_loss: 1.3031 - val_aux1_loss: 1.5321 - val_aux2_loss: 1.1582 - val_main_accuracy: 0.8284 - val_aux1_accuracy: 0.8462 - val_aux2_accuracy: 0.8491\n",
            "Epoch 74/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0175 - main_loss: 0.0109 - aux1_loss: 0.0127 - aux2_loss: 0.0091 - main_accuracy: 0.9963 - aux1_accuracy: 0.9963 - aux2_accuracy: 0.9970"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0175 - main_loss: 0.0109 - aux1_loss: 0.0127 - aux2_loss: 0.0091 - main_accuracy: 0.9963 - aux1_accuracy: 0.9963 - aux2_accuracy: 0.9970 - val_loss: 1.7184 - val_main_loss: 1.0925 - val_aux1_loss: 1.0320 - val_aux2_loss: 1.0544 - val_main_accuracy: 0.8521 - val_aux1_accuracy: 0.8432 - val_aux2_accuracy: 0.8462\n",
            "Epoch 75/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0662 - main_loss: 0.0498 - aux1_loss: 0.0203 - aux2_loss: 0.0343 - main_accuracy: 0.9866 - aux1_accuracy: 0.9940 - aux2_accuracy: 0.9929"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 127ms/step - loss: 0.0662 - main_loss: 0.0498 - aux1_loss: 0.0203 - aux2_loss: 0.0343 - main_accuracy: 0.9866 - aux1_accuracy: 0.9940 - aux2_accuracy: 0.9929 - val_loss: 1.3582 - val_main_loss: 0.8027 - val_aux1_loss: 1.0086 - val_aux2_loss: 0.8429 - val_main_accuracy: 0.8669 - val_aux1_accuracy: 0.8609 - val_aux2_accuracy: 0.8757\n",
            "Epoch 76/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0606 - main_loss: 0.0402 - aux1_loss: 0.0333 - aux2_loss: 0.0347 - main_accuracy: 0.9873 - aux1_accuracy: 0.9911 - aux2_accuracy: 0.9907"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0606 - main_loss: 0.0402 - aux1_loss: 0.0333 - aux2_loss: 0.0347 - main_accuracy: 0.9873 - aux1_accuracy: 0.9911 - aux2_accuracy: 0.9907 - val_loss: 1.4974 - val_main_loss: 0.9091 - val_aux1_loss: 1.0000 - val_aux2_loss: 0.9613 - val_main_accuracy: 0.8609 - val_aux1_accuracy: 0.8817 - val_aux2_accuracy: 0.8728\n",
            "Epoch 77/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0266 - main_loss: 0.0183 - aux1_loss: 0.0115 - aux2_loss: 0.0161 - main_accuracy: 0.9937 - aux1_accuracy: 0.9963 - aux2_accuracy: 0.9937"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0266 - main_loss: 0.0183 - aux1_loss: 0.0115 - aux2_loss: 0.0161 - main_accuracy: 0.9937 - aux1_accuracy: 0.9963 - aux2_accuracy: 0.9937 - val_loss: 1.4013 - val_main_loss: 0.8325 - val_aux1_loss: 0.9601 - val_aux2_loss: 0.9360 - val_main_accuracy: 0.8757 - val_aux1_accuracy: 0.8757 - val_aux2_accuracy: 0.8846\n",
            "Epoch 78/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0648 - main_loss: 0.0478 - aux1_loss: 0.0235 - aux2_loss: 0.0331 - main_accuracy: 0.9855 - aux1_accuracy: 0.9929 - aux2_accuracy: 0.9899"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0648 - main_loss: 0.0478 - aux1_loss: 0.0235 - aux2_loss: 0.0331 - main_accuracy: 0.9855 - aux1_accuracy: 0.9929 - aux2_accuracy: 0.9899 - val_loss: 1.4171 - val_main_loss: 0.8176 - val_aux1_loss: 1.0775 - val_aux2_loss: 0.9207 - val_main_accuracy: 0.8580 - val_aux1_accuracy: 0.8521 - val_aux2_accuracy: 0.8580\n",
            "Epoch 79/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0753 - main_loss: 0.0537 - aux1_loss: 0.0317 - aux2_loss: 0.0403 - main_accuracy: 0.9836 - aux1_accuracy: 0.9892 - aux2_accuracy: 0.9877"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0753 - main_loss: 0.0537 - aux1_loss: 0.0317 - aux2_loss: 0.0403 - main_accuracy: 0.9836 - aux1_accuracy: 0.9892 - aux2_accuracy: 0.9877 - val_loss: 1.0881 - val_main_loss: 0.6024 - val_aux1_loss: 0.9290 - val_aux2_loss: 0.6901 - val_main_accuracy: 0.8817 - val_aux1_accuracy: 0.8876 - val_aux2_accuracy: 0.8817\n",
            "Epoch 80/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0196 - main_loss: 0.0148 - aux1_loss: 0.0083 - aux2_loss: 0.0075 - main_accuracy: 0.9955 - aux1_accuracy: 0.9966 - aux2_accuracy: 0.9981"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 129ms/step - loss: 0.0196 - main_loss: 0.0148 - aux1_loss: 0.0083 - aux2_loss: 0.0075 - main_accuracy: 0.9955 - aux1_accuracy: 0.9966 - aux2_accuracy: 0.9981 - val_loss: 1.4504 - val_main_loss: 0.9257 - val_aux1_loss: 0.8846 - val_aux2_loss: 0.8645 - val_main_accuracy: 0.8550 - val_aux1_accuracy: 0.8935 - val_aux2_accuracy: 0.8817\n",
            "Epoch 81/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0990 - main_loss: 0.0745 - aux1_loss: 0.0299 - aux2_loss: 0.0519 - main_accuracy: 0.9795 - aux1_accuracy: 0.9907 - aux2_accuracy: 0.9859"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0990 - main_loss: 0.0745 - aux1_loss: 0.0299 - aux2_loss: 0.0519 - main_accuracy: 0.9795 - aux1_accuracy: 0.9907 - aux2_accuracy: 0.9859 - val_loss: 1.5985 - val_main_loss: 0.9706 - val_aux1_loss: 1.0392 - val_aux2_loss: 1.0538 - val_main_accuracy: 0.8402 - val_aux1_accuracy: 0.8609 - val_aux2_accuracy: 0.8550\n",
            "Epoch 82/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.1624 - main_loss: 0.1054 - aux1_loss: 0.1025 - aux2_loss: 0.0875 - main_accuracy: 0.9724 - aux1_accuracy: 0.9717 - aux2_accuracy: 0.9754"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.1624 - main_loss: 0.1054 - aux1_loss: 0.1025 - aux2_loss: 0.0875 - main_accuracy: 0.9724 - aux1_accuracy: 0.9717 - aux2_accuracy: 0.9754 - val_loss: 1.3340 - val_main_loss: 0.8406 - val_aux1_loss: 0.8063 - val_aux2_loss: 0.8383 - val_main_accuracy: 0.8343 - val_aux1_accuracy: 0.8491 - val_aux2_accuracy: 0.8491\n",
            "Epoch 83/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0710 - main_loss: 0.0506 - aux1_loss: 0.0328 - aux2_loss: 0.0350 - main_accuracy: 0.9855 - aux1_accuracy: 0.9896 - aux2_accuracy: 0.9892"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0710 - main_loss: 0.0506 - aux1_loss: 0.0328 - aux2_loss: 0.0350 - main_accuracy: 0.9855 - aux1_accuracy: 0.9896 - aux2_accuracy: 0.9892 - val_loss: 1.7921 - val_main_loss: 1.0423 - val_aux1_loss: 1.2551 - val_aux2_loss: 1.2443 - val_main_accuracy: 0.8373 - val_aux1_accuracy: 0.8462 - val_aux2_accuracy: 0.8402\n",
            "Epoch 84/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0281 - main_loss: 0.0197 - aux1_loss: 0.0125 - aux2_loss: 0.0156 - main_accuracy: 0.9948 - aux1_accuracy: 0.9959 - aux2_accuracy: 0.9955"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0281 - main_loss: 0.0197 - aux1_loss: 0.0125 - aux2_loss: 0.0156 - main_accuracy: 0.9948 - aux1_accuracy: 0.9959 - aux2_accuracy: 0.9955 - val_loss: 1.5314 - val_main_loss: 0.9431 - val_aux1_loss: 0.9673 - val_aux2_loss: 0.9937 - val_main_accuracy: 0.8905 - val_aux1_accuracy: 0.8876 - val_aux2_accuracy: 0.8964\n",
            "Epoch 85/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0317 - main_loss: 0.0202 - aux1_loss: 0.0256 - aux2_loss: 0.0128 - main_accuracy: 0.9922 - aux1_accuracy: 0.9926 - aux2_accuracy: 0.9963"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0317 - main_loss: 0.0202 - aux1_loss: 0.0256 - aux2_loss: 0.0128 - main_accuracy: 0.9922 - aux1_accuracy: 0.9926 - aux2_accuracy: 0.9963 - val_loss: 1.9101 - val_main_loss: 1.1481 - val_aux1_loss: 1.1839 - val_aux2_loss: 1.3562 - val_main_accuracy: 0.8609 - val_aux1_accuracy: 0.8580 - val_aux2_accuracy: 0.8580\n",
            "Epoch 86/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.1885 - main_loss: 0.1281 - aux1_loss: 0.0915 - aux2_loss: 0.1097 - main_accuracy: 0.9687 - aux1_accuracy: 0.9795 - aux2_accuracy: 0.9773"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.1885 - main_loss: 0.1281 - aux1_loss: 0.0915 - aux2_loss: 0.1097 - main_accuracy: 0.9687 - aux1_accuracy: 0.9795 - aux2_accuracy: 0.9773 - val_loss: 1.8610 - val_main_loss: 1.1229 - val_aux1_loss: 1.3833 - val_aux2_loss: 1.0769 - val_main_accuracy: 0.7870 - val_aux1_accuracy: 0.8254 - val_aux2_accuracy: 0.7959\n",
            "Epoch 87/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0839 - main_loss: 0.0639 - aux1_loss: 0.0304 - aux2_loss: 0.0362 - main_accuracy: 0.9758 - aux1_accuracy: 0.9911 - aux2_accuracy: 0.9881"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0839 - main_loss: 0.0639 - aux1_loss: 0.0304 - aux2_loss: 0.0362 - main_accuracy: 0.9758 - aux1_accuracy: 0.9911 - aux2_accuracy: 0.9881 - val_loss: 1.7013 - val_main_loss: 1.0400 - val_aux1_loss: 1.2260 - val_aux2_loss: 0.9783 - val_main_accuracy: 0.8314 - val_aux1_accuracy: 0.8639 - val_aux2_accuracy: 0.8521\n",
            "Epoch 88/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0898 - main_loss: 0.0552 - aux1_loss: 0.0516 - aux2_loss: 0.0636 - main_accuracy: 0.9859 - aux1_accuracy: 0.9888 - aux2_accuracy: 0.9855"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 130ms/step - loss: 0.0898 - main_loss: 0.0552 - aux1_loss: 0.0516 - aux2_loss: 0.0636 - main_accuracy: 0.9859 - aux1_accuracy: 0.9888 - aux2_accuracy: 0.9855 - val_loss: 1.0365 - val_main_loss: 0.5544 - val_aux1_loss: 0.9128 - val_aux2_loss: 0.6942 - val_main_accuracy: 0.8817 - val_aux1_accuracy: 0.9053 - val_aux2_accuracy: 0.8905\n",
            "Epoch 89/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0558 - main_loss: 0.0405 - aux1_loss: 0.0188 - aux2_loss: 0.0326 - main_accuracy: 0.9903 - aux1_accuracy: 0.9940 - aux2_accuracy: 0.9892"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 130ms/step - loss: 0.0558 - main_loss: 0.0405 - aux1_loss: 0.0188 - aux2_loss: 0.0326 - main_accuracy: 0.9903 - aux1_accuracy: 0.9940 - aux2_accuracy: 0.9892 - val_loss: 1.5616 - val_main_loss: 0.8321 - val_aux1_loss: 1.4133 - val_aux2_loss: 1.0184 - val_main_accuracy: 0.8343 - val_aux1_accuracy: 0.8402 - val_aux2_accuracy: 0.8343\n",
            "Epoch 90/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0715 - main_loss: 0.0480 - aux1_loss: 0.0441 - aux2_loss: 0.0344 - main_accuracy: 0.9885 - aux1_accuracy: 0.9896 - aux2_accuracy: 0.9888"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0715 - main_loss: 0.0480 - aux1_loss: 0.0441 - aux2_loss: 0.0344 - main_accuracy: 0.9885 - aux1_accuracy: 0.9896 - aux2_accuracy: 0.9888 - val_loss: 2.0006 - val_main_loss: 1.1225 - val_aux1_loss: 1.4680 - val_aux2_loss: 1.4590 - val_main_accuracy: 0.7722 - val_aux1_accuracy: 0.7840 - val_aux2_accuracy: 0.7781\n",
            "Epoch 91/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0776 - main_loss: 0.0538 - aux1_loss: 0.0399 - aux2_loss: 0.0392 - main_accuracy: 0.9870 - aux1_accuracy: 0.9903 - aux2_accuracy: 0.9929"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0776 - main_loss: 0.0538 - aux1_loss: 0.0399 - aux2_loss: 0.0392 - main_accuracy: 0.9870 - aux1_accuracy: 0.9903 - aux2_accuracy: 0.9929 - val_loss: 1.2512 - val_main_loss: 0.7426 - val_aux1_loss: 0.9343 - val_aux2_loss: 0.7610 - val_main_accuracy: 0.8846 - val_aux1_accuracy: 0.8757 - val_aux2_accuracy: 0.8846\n",
            "Epoch 92/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0514 - main_loss: 0.0360 - aux1_loss: 0.0204 - aux2_loss: 0.0310 - main_accuracy: 0.9896 - aux1_accuracy: 0.9937 - aux2_accuracy: 0.9896"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 127ms/step - loss: 0.0514 - main_loss: 0.0360 - aux1_loss: 0.0204 - aux2_loss: 0.0310 - main_accuracy: 0.9896 - aux1_accuracy: 0.9937 - aux2_accuracy: 0.9896 - val_loss: 1.3608 - val_main_loss: 0.7902 - val_aux1_loss: 1.0356 - val_aux2_loss: 0.8662 - val_main_accuracy: 0.8550 - val_aux1_accuracy: 0.8639 - val_aux2_accuracy: 0.8639\n",
            "Epoch 93/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0719 - main_loss: 0.0516 - aux1_loss: 0.0279 - aux2_loss: 0.0398 - main_accuracy: 0.9866 - aux1_accuracy: 0.9918 - aux2_accuracy: 0.9888"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 130ms/step - loss: 0.0719 - main_loss: 0.0516 - aux1_loss: 0.0279 - aux2_loss: 0.0398 - main_accuracy: 0.9866 - aux1_accuracy: 0.9918 - aux2_accuracy: 0.9888 - val_loss: 1.1750 - val_main_loss: 0.6694 - val_aux1_loss: 0.8889 - val_aux2_loss: 0.7966 - val_main_accuracy: 0.8817 - val_aux1_accuracy: 0.8905 - val_aux2_accuracy: 0.8757\n",
            "Epoch 94/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0654 - main_loss: 0.0513 - aux1_loss: 0.0146 - aux2_loss: 0.0325 - main_accuracy: 0.9888 - aux1_accuracy: 0.9944 - aux2_accuracy: 0.9911"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0654 - main_loss: 0.0513 - aux1_loss: 0.0146 - aux2_loss: 0.0325 - main_accuracy: 0.9888 - aux1_accuracy: 0.9944 - aux2_accuracy: 0.9911 - val_loss: 1.0635 - val_main_loss: 0.5753 - val_aux1_loss: 0.8652 - val_aux2_loss: 0.7622 - val_main_accuracy: 0.8935 - val_aux1_accuracy: 0.8787 - val_aux2_accuracy: 0.8757\n",
            "Epoch 95/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0072 - main_loss: 0.0049 - aux1_loss: 0.0039 - aux2_loss: 0.0038 - main_accuracy: 0.9989 - aux1_accuracy: 0.9985 - aux2_accuracy: 0.9993"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0072 - main_loss: 0.0049 - aux1_loss: 0.0039 - aux2_loss: 0.0038 - main_accuracy: 0.9989 - aux1_accuracy: 0.9985 - aux2_accuracy: 0.9993 - val_loss: 1.4628 - val_main_loss: 0.8515 - val_aux1_loss: 1.0708 - val_aux2_loss: 0.9669 - val_main_accuracy: 0.8669 - val_aux1_accuracy: 0.8905 - val_aux2_accuracy: 0.8787\n",
            "Epoch 96/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0643 - main_loss: 0.0482 - aux1_loss: 0.0244 - aux2_loss: 0.0293 - main_accuracy: 0.9903 - aux1_accuracy: 0.9963 - aux2_accuracy: 0.9926"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0643 - main_loss: 0.0482 - aux1_loss: 0.0244 - aux2_loss: 0.0293 - main_accuracy: 0.9903 - aux1_accuracy: 0.9963 - aux2_accuracy: 0.9926 - val_loss: 2.2674 - val_main_loss: 1.3333 - val_aux1_loss: 1.5443 - val_aux2_loss: 1.5691 - val_main_accuracy: 0.7840 - val_aux1_accuracy: 0.8402 - val_aux2_accuracy: 0.8166\n",
            "Epoch 97/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.1448 - main_loss: 0.0969 - aux1_loss: 0.0661 - aux2_loss: 0.0934 - main_accuracy: 0.9765 - aux1_accuracy: 0.9818 - aux2_accuracy: 0.9792"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.1448 - main_loss: 0.0969 - aux1_loss: 0.0661 - aux2_loss: 0.0934 - main_accuracy: 0.9765 - aux1_accuracy: 0.9818 - aux2_accuracy: 0.9792 - val_loss: 1.4946 - val_main_loss: 0.9073 - val_aux1_loss: 0.8054 - val_aux2_loss: 1.1522 - val_main_accuracy: 0.8521 - val_aux1_accuracy: 0.8757 - val_aux2_accuracy: 0.8491\n",
            "Epoch 98/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0749 - main_loss: 0.0500 - aux1_loss: 0.0345 - aux2_loss: 0.0483 - main_accuracy: 0.9862 - aux1_accuracy: 0.9907 - aux2_accuracy: 0.9866"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 130ms/step - loss: 0.0749 - main_loss: 0.0500 - aux1_loss: 0.0345 - aux2_loss: 0.0483 - main_accuracy: 0.9862 - aux1_accuracy: 0.9907 - aux2_accuracy: 0.9866 - val_loss: 1.2585 - val_main_loss: 0.7318 - val_aux1_loss: 1.0203 - val_aux2_loss: 0.7355 - val_main_accuracy: 0.8491 - val_aux1_accuracy: 0.8817 - val_aux2_accuracy: 0.8669\n",
            "Epoch 99/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0348 - main_loss: 0.0251 - aux1_loss: 0.0165 - aux2_loss: 0.0159 - main_accuracy: 0.9940 - aux1_accuracy: 0.9959 - aux2_accuracy: 0.9944"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0348 - main_loss: 0.0251 - aux1_loss: 0.0165 - aux2_loss: 0.0159 - main_accuracy: 0.9940 - aux1_accuracy: 0.9959 - aux2_accuracy: 0.9944 - val_loss: 1.1466 - val_main_loss: 0.6350 - val_aux1_loss: 0.9721 - val_aux2_loss: 0.7333 - val_main_accuracy: 0.8698 - val_aux1_accuracy: 0.8817 - val_aux2_accuracy: 0.8757\n",
            "Epoch 100/100\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0176 - main_loss: 0.0121 - aux1_loss: 0.0122 - aux2_loss: 0.0062 - main_accuracy: 0.9966 - aux1_accuracy: 0.9966 - aux2_accuracy: 0.9985"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,main_loss,aux1_loss,aux2_loss,main_accuracy,aux1_accuracy,aux2_accuracy,val_loss,val_main_loss,val_aux1_loss,val_aux2_loss,val_main_accuracy,val_aux1_accuracy,val_aux2_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 11s 128ms/step - loss: 0.0176 - main_loss: 0.0121 - aux1_loss: 0.0122 - aux2_loss: 0.0062 - main_accuracy: 0.9966 - aux1_accuracy: 0.9966 - aux2_accuracy: 0.9985 - val_loss: 1.3388 - val_main_loss: 0.7516 - val_aux1_loss: 1.0497 - val_aux2_loss: 0.9077 - val_main_accuracy: 0.8698 - val_aux1_accuracy: 0.8994 - val_aux2_accuracy: 0.8698\n"
          ]
        }
      ],
      "source": [
        "googlenet_1 = googlenet()\n",
        "googlenet_1=model_train(googlenet_1,x_train,Y_train,x_validation,Y_validation,\"googlenet_1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYkF5MhKtjM9"
      },
      "source": [
        "\n",
        "\n",
        "> Train model with another preprocessing technique\n",
        "\n",
        "note these technique is the best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duf0M_eWheTf"
      },
      "outputs": [],
      "source": [
        "# creating the image data generator to standardize images\n",
        "train_datagen = ImageDataGenerator(featurewise_center=True,\n",
        "                             featurewise_std_normalization=True,\n",
        "                            zoom_range=0.15,\n",
        "                            width_shift_range=0.2,\n",
        "                            height_shift_range=0.2,\n",
        "                            shear_range=0.15)\n",
        "test_datagen=ImageDataGenerator(featurewise_center=True,\n",
        "                             featurewise_std_normalization=True)\n",
        "# calculating the mean on the training dataset\n",
        "\n",
        "train_datagen.fit(X_train)\n",
        "test_datagen.fit(X_validation)  \n",
        "# preparing iterators to scale images\n",
        "train_iterator = tf.data.Dataset.from_generator(\n",
        "    lambda: train_datagen.flow(X_train, y_train,batch_size=32), \n",
        "                        output_signature=(tf.TensorSpec(shape=(None, 224, 224, 3),dtype=tf.float32),\n",
        "                                          tf.TensorSpec(shape=(None, 6),dtype=tf.float32))       \n",
        "                            )\n",
        "\n",
        "train_iterator = train_iterator.prefetch(1)\n",
        "# train_datagen.flow(X_train, y_train, batch_size=64)\n",
        "test_iterator = tf.data.Dataset.from_generator(\n",
        "    lambda: test_datagen.flow(X_validation, y_validation, batch_size=32),  \n",
        "                              output_signature=(tf.TensorSpec(shape=(None, 224, 224, 3),dtype=tf.float32),\n",
        "                                               tf.TensorSpec(shape=(None, 6),dtype=tf.float32))\n",
        "                            )\n",
        "test_iterator = test_iterator.prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCd3ncfPt0n4"
      },
      "outputs": [],
      "source": [
        "def model_train_generator(model,train_iter,validation_iter,name_of_model,num_epoch=10,lr=1e-3):\n",
        "  if name_of_model ==\"googlenet_2\":\n",
        "       model.compile(loss='categorical_crossentropy', \n",
        "                  loss_weights={'main': 1.0, 'aux1': 0.3, 'aux2': 0.3},\n",
        "                  optimizer=Adam(learning_rate=lr),metrics = [\"accuracy\"])\n",
        "  else:\n",
        "       model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=lr),metrics=[\"accuracy\"])\n",
        "  #es=EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=20)\n",
        "  mc = ModelCheckpoint('/content/drive/MyDrive/NNproject/'+name_of_model+'.h5', monitor='val_accuracy', mode='max', save_best_only=True)\n",
        "  model.fit(train_iterator,epochs=num_epoch,steps_per_epoch= len(train_data)//16,verbose=1,callbacks=[mc],shuffle=True)\n",
        "\n",
        "  #evaluate model\n",
        "  acc = model.evaluate(test_iterator, steps=len(validation_data))\n",
        "  print(\"validation accuracy \"+str(acc))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmUsEbZvjmEE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75ab69c9-c60a-4871-ce5e-c01d4d5790cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.8253 - accuracy: 0.7544"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 42s 374ms/step - loss: 0.8253 - accuracy: 0.7544\n",
            "Epoch 2/8\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.1968 - accuracy: 0.9318"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 31s 370ms/step - loss: 0.1968 - accuracy: 0.9318\n",
            "Epoch 3/8\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.1313 - accuracy: 0.9563"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 28s 341ms/step - loss: 0.1313 - accuracy: 0.9563\n",
            "Epoch 4/8\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 0.9687"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 29s 348ms/step - loss: 0.0965 - accuracy: 0.9687\n",
            "Epoch 5/8\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.9781"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 29s 344ms/step - loss: 0.0617 - accuracy: 0.9781\n",
            "Epoch 6/8\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9812"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 28s 341ms/step - loss: 0.0554 - accuracy: 0.9812\n",
            "Epoch 7/8\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 0.9804"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 28s 343ms/step - loss: 0.0629 - accuracy: 0.9804\n",
            "Epoch 8/8\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0378 - accuracy: 0.9876"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83/83 [==============================] - 28s 342ms/step - loss: 0.0378 - accuracy: 0.9876\n",
            "338/338 [==============================] - 56s 166ms/step - loss: 0.1422 - accuracy: 0.9527\n",
            "validation accuracy [0.14217659831047058, 0.9526740908622742]\n"
          ]
        }
      ],
      "source": [
        "#best vgg model\n",
        "vggg_2=vgg_model()\n",
        "vggg_2=model_train_generator(vggg_2,train_iterator,test_iterator,'vggg_2',8,lr=1e-3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TL-cEBmvicU",
        "outputId": "46039dd6-55e4-48c9-983d-1cc3e99fa20d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "83/83 [==============================] - ETA: 0s - loss: 6.6957 - accuracy: 0.5299"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 31s 324ms/step - loss: 6.6957 - accuracy: 0.5299\n",
            "Epoch 2/20\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.8144 - accuracy: 0.7121"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 27s 323ms/step - loss: 0.8144 - accuracy: 0.7121\n",
            "Epoch 3/20\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7541 - accuracy: 0.7400"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 28s 335ms/step - loss: 0.7541 - accuracy: 0.7400\n",
            "Epoch 4/20\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.6658 - accuracy: 0.7668"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 27s 320ms/step - loss: 0.6658 - accuracy: 0.7668\n",
            "Epoch 5/20\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.5796 - accuracy: 0.8071"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 27s 321ms/step - loss: 0.5796 - accuracy: 0.8071\n",
            "Epoch 6/20\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.5578 - accuracy: 0.8071"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 26s 318ms/step - loss: 0.5578 - accuracy: 0.8071\n",
            "Epoch 7/20\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.4897 - accuracy: 0.8225"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 27s 320ms/step - loss: 0.4897 - accuracy: 0.8225\n",
            "Epoch 8/20\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.4569 - accuracy: 0.8395"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 27s 319ms/step - loss: 0.4569 - accuracy: 0.8395\n",
            "Epoch 9/20\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.4291 - accuracy: 0.8538"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 27s 326ms/step - loss: 0.4291 - accuracy: 0.8538\n",
            "Epoch 10/20\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.4776 - accuracy: 0.8440"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 29s 354ms/step - loss: 0.4776 - accuracy: 0.8440\n",
            "Epoch 11/20\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.4002 - accuracy: 0.8625"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 27s 323ms/step - loss: 0.4002 - accuracy: 0.8625\n",
            "Epoch 12/20\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.4139 - accuracy: 0.8580"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 26s 319ms/step - loss: 0.4139 - accuracy: 0.8580\n",
            "Epoch 13/20\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.3965 - accuracy: 0.8700"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 27s 320ms/step - loss: 0.3965 - accuracy: 0.8700\n",
            "Epoch 14/20\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.3497 - accuracy: 0.8870"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 27s 320ms/step - loss: 0.3497 - accuracy: 0.8870\n",
            "Epoch 15/20\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.3784 - accuracy: 0.8757"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 26s 319ms/step - loss: 0.3784 - accuracy: 0.8757\n",
            "Epoch 16/20\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.3372 - accuracy: 0.8855"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 26s 319ms/step - loss: 0.3372 - accuracy: 0.8855\n",
            "Epoch 17/20\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.3026 - accuracy: 0.9039"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 28s 333ms/step - loss: 0.3026 - accuracy: 0.9039\n",
            "Epoch 18/20\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.2636 - accuracy: 0.9084"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 26s 319ms/step - loss: 0.2636 - accuracy: 0.9084\n",
            "Epoch 19/20\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.3393 - accuracy: 0.8873"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 26s 318ms/step - loss: 0.3393 - accuracy: 0.8873\n",
            "Epoch 20/20\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.3607 - accuracy: 0.8858"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83/83 [==============================] - 26s 319ms/step - loss: 0.3607 - accuracy: 0.8858\n",
            "338/338 [==============================] - 36s 104ms/step - loss: 0.7412 - accuracy: 0.7842\n",
            "validation accuracy [0.7411804795265198, 0.7842439413070679]\n"
          ]
        }
      ],
      "source": [
        "resnet50_2=Pretrained_Resnet50()\n",
        "resnet50_2=model_train_generator(resnet50_2,train_iterator,test_iterator,'resnet50_2',20,1e-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0uHfaGDDud_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3af65072-09cf-4709-cedd-86995bcdf163"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 2.2289 - main_loss: 1.4322 - aux1_loss: 1.3013 - aux2_loss: 1.3544 - main_accuracy: 0.4670 - aux1_accuracy: 0.5390 - aux2_accuracy: 0.4817"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 37s 361ms/step - loss: 2.2289 - main_loss: 1.4322 - aux1_loss: 1.3013 - aux2_loss: 1.3544 - main_accuracy: 0.4670 - aux1_accuracy: 0.5390 - aux2_accuracy: 0.4817\n",
            "Epoch 2/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 1.7304 - main_loss: 1.1306 - aux1_loss: 0.9403 - aux2_loss: 1.0591 - main_accuracy: 0.5806 - aux1_accuracy: 0.6579 - aux2_accuracy: 0.6074"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 28s 332ms/step - loss: 1.7304 - main_loss: 1.1306 - aux1_loss: 0.9403 - aux2_loss: 1.0591 - main_accuracy: 0.5806 - aux1_accuracy: 0.6579 - aux2_accuracy: 0.6074\n",
            "Epoch 3/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 1.4759 - main_loss: 0.9653 - aux1_loss: 0.8007 - aux2_loss: 0.9011 - main_accuracy: 0.6631 - aux1_accuracy: 0.7257 - aux2_accuracy: 0.6914"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 28s 332ms/step - loss: 1.4759 - main_loss: 0.9653 - aux1_loss: 0.8007 - aux2_loss: 0.9011 - main_accuracy: 0.6631 - aux1_accuracy: 0.7257 - aux2_accuracy: 0.6914\n",
            "Epoch 4/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 1.2444 - main_loss: 0.8109 - aux1_loss: 0.6779 - aux2_loss: 0.7673 - main_accuracy: 0.7265 - aux1_accuracy: 0.7630 - aux2_accuracy: 0.7306"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 29s 350ms/step - loss: 1.2444 - main_loss: 0.8109 - aux1_loss: 0.6779 - aux2_loss: 0.7673 - main_accuracy: 0.7265 - aux1_accuracy: 0.7630 - aux2_accuracy: 0.7306\n",
            "Epoch 5/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 1.2631 - main_loss: 0.8231 - aux1_loss: 0.6910 - aux2_loss: 0.7757 - main_accuracy: 0.7257 - aux1_accuracy: 0.7491 - aux2_accuracy: 0.7393"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 27s 330ms/step - loss: 1.2631 - main_loss: 0.8231 - aux1_loss: 0.6910 - aux2_loss: 0.7757 - main_accuracy: 0.7257 - aux1_accuracy: 0.7491 - aux2_accuracy: 0.7393\n",
            "Epoch 6/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 1.0616 - main_loss: 0.6905 - aux1_loss: 0.5727 - aux2_loss: 0.6643 - main_accuracy: 0.7702 - aux1_accuracy: 0.7973 - aux2_accuracy: 0.7732"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 28s 334ms/step - loss: 1.0616 - main_loss: 0.6905 - aux1_loss: 0.5727 - aux2_loss: 0.6643 - main_accuracy: 0.7702 - aux1_accuracy: 0.7973 - aux2_accuracy: 0.7732\n",
            "Epoch 7/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.9537 - main_loss: 0.6267 - aux1_loss: 0.5101 - aux2_loss: 0.5796 - main_accuracy: 0.7864 - aux1_accuracy: 0.8195 - aux2_accuracy: 0.8041"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 28s 334ms/step - loss: 0.9537 - main_loss: 0.6267 - aux1_loss: 0.5101 - aux2_loss: 0.5796 - main_accuracy: 0.7864 - aux1_accuracy: 0.8195 - aux2_accuracy: 0.8041\n",
            "Epoch 8/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.9187 - main_loss: 0.5993 - aux1_loss: 0.4935 - aux2_loss: 0.5712 - main_accuracy: 0.8014 - aux1_accuracy: 0.8278 - aux2_accuracy: 0.8139"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 28s 332ms/step - loss: 0.9187 - main_loss: 0.5993 - aux1_loss: 0.4935 - aux2_loss: 0.5712 - main_accuracy: 0.8014 - aux1_accuracy: 0.8278 - aux2_accuracy: 0.8139\n",
            "Epoch 9/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.8379 - main_loss: 0.5503 - aux1_loss: 0.4457 - aux2_loss: 0.5127 - main_accuracy: 0.8161 - aux1_accuracy: 0.8444 - aux2_accuracy: 0.8263"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 27s 329ms/step - loss: 0.8379 - main_loss: 0.5503 - aux1_loss: 0.4457 - aux2_loss: 0.5127 - main_accuracy: 0.8161 - aux1_accuracy: 0.8444 - aux2_accuracy: 0.8263\n",
            "Epoch 10/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7832 - main_loss: 0.5140 - aux1_loss: 0.4203 - aux2_loss: 0.4771 - main_accuracy: 0.8255 - aux1_accuracy: 0.8515 - aux2_accuracy: 0.8406"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 28s 333ms/step - loss: 0.7832 - main_loss: 0.5140 - aux1_loss: 0.4203 - aux2_loss: 0.4771 - main_accuracy: 0.8255 - aux1_accuracy: 0.8515 - aux2_accuracy: 0.8406\n",
            "Epoch 11/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7218 - main_loss: 0.4796 - aux1_loss: 0.3659 - aux2_loss: 0.4418 - main_accuracy: 0.8406 - aux1_accuracy: 0.8779 - aux2_accuracy: 0.8459"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 29s 351ms/step - loss: 0.7218 - main_loss: 0.4796 - aux1_loss: 0.3659 - aux2_loss: 0.4418 - main_accuracy: 0.8406 - aux1_accuracy: 0.8779 - aux2_accuracy: 0.8459\n",
            "Epoch 12/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.6721 - main_loss: 0.4439 - aux1_loss: 0.3471 - aux2_loss: 0.4135 - main_accuracy: 0.8549 - aux1_accuracy: 0.8866 - aux2_accuracy: 0.8568"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 28s 343ms/step - loss: 0.6721 - main_loss: 0.4439 - aux1_loss: 0.3471 - aux2_loss: 0.4135 - main_accuracy: 0.8549 - aux1_accuracy: 0.8866 - aux2_accuracy: 0.8568\n",
            "Epoch 13/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.6121 - main_loss: 0.4076 - aux1_loss: 0.3033 - aux2_loss: 0.3783 - main_accuracy: 0.8591 - aux1_accuracy: 0.9005 - aux2_accuracy: 0.8670"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 28s 336ms/step - loss: 0.6121 - main_loss: 0.4076 - aux1_loss: 0.3033 - aux2_loss: 0.3783 - main_accuracy: 0.8591 - aux1_accuracy: 0.9005 - aux2_accuracy: 0.8670\n",
            "Epoch 14/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.5187 - main_loss: 0.3436 - aux1_loss: 0.2723 - aux2_loss: 0.3114 - main_accuracy: 0.8877 - aux1_accuracy: 0.9039 - aux2_accuracy: 0.8956"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 28s 333ms/step - loss: 0.5187 - main_loss: 0.3436 - aux1_loss: 0.2723 - aux2_loss: 0.3114 - main_accuracy: 0.8877 - aux1_accuracy: 0.9039 - aux2_accuracy: 0.8956\n",
            "Epoch 15/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.5439 - main_loss: 0.3607 - aux1_loss: 0.2747 - aux2_loss: 0.3359 - main_accuracy: 0.8772 - aux1_accuracy: 0.9081 - aux2_accuracy: 0.8851"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 28s 335ms/step - loss: 0.5439 - main_loss: 0.3607 - aux1_loss: 0.2747 - aux2_loss: 0.3359 - main_accuracy: 0.8772 - aux1_accuracy: 0.9081 - aux2_accuracy: 0.8851\n",
            "Epoch 16/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.4446 - main_loss: 0.2890 - aux1_loss: 0.2382 - aux2_loss: 0.2805 - main_accuracy: 0.9028 - aux1_accuracy: 0.9209 - aux2_accuracy: 0.9066"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 27s 330ms/step - loss: 0.4446 - main_loss: 0.2890 - aux1_loss: 0.2382 - aux2_loss: 0.2805 - main_accuracy: 0.9028 - aux1_accuracy: 0.9209 - aux2_accuracy: 0.9066\n",
            "Epoch 17/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.4641 - main_loss: 0.3119 - aux1_loss: 0.2372 - aux2_loss: 0.2699 - main_accuracy: 0.8930 - aux1_accuracy: 0.9182 - aux2_accuracy: 0.9047"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 27s 331ms/step - loss: 0.4641 - main_loss: 0.3119 - aux1_loss: 0.2372 - aux2_loss: 0.2699 - main_accuracy: 0.8930 - aux1_accuracy: 0.9182 - aux2_accuracy: 0.9047\n",
            "Epoch 18/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.4575 - main_loss: 0.3064 - aux1_loss: 0.2304 - aux2_loss: 0.2733 - main_accuracy: 0.8926 - aux1_accuracy: 0.9231 - aux2_accuracy: 0.9126"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 28s 342ms/step - loss: 0.4575 - main_loss: 0.3064 - aux1_loss: 0.2304 - aux2_loss: 0.2733 - main_accuracy: 0.8926 - aux1_accuracy: 0.9231 - aux2_accuracy: 0.9126\n",
            "Epoch 19/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.3641 - main_loss: 0.2426 - aux1_loss: 0.1878 - aux2_loss: 0.2173 - main_accuracy: 0.9167 - aux1_accuracy: 0.9348 - aux2_accuracy: 0.9246"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 28s 336ms/step - loss: 0.3641 - main_loss: 0.2426 - aux1_loss: 0.1878 - aux2_loss: 0.2173 - main_accuracy: 0.9167 - aux1_accuracy: 0.9348 - aux2_accuracy: 0.9246\n",
            "Epoch 20/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.3753 - main_loss: 0.2536 - aux1_loss: 0.1806 - aux2_loss: 0.2251 - main_accuracy: 0.9190 - aux1_accuracy: 0.9386 - aux2_accuracy: 0.9243"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 27s 329ms/step - loss: 0.3753 - main_loss: 0.2536 - aux1_loss: 0.1806 - aux2_loss: 0.2251 - main_accuracy: 0.9190 - aux1_accuracy: 0.9386 - aux2_accuracy: 0.9243\n",
            "Epoch 21/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.3513 - main_loss: 0.2344 - aux1_loss: 0.1742 - aux2_loss: 0.2155 - main_accuracy: 0.9243 - aux1_accuracy: 0.9439 - aux2_accuracy: 0.9288"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 28s 332ms/step - loss: 0.3513 - main_loss: 0.2344 - aux1_loss: 0.1742 - aux2_loss: 0.2155 - main_accuracy: 0.9243 - aux1_accuracy: 0.9439 - aux2_accuracy: 0.9288\n",
            "Epoch 22/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.3094 - main_loss: 0.2066 - aux1_loss: 0.1538 - aux2_loss: 0.1889 - main_accuracy: 0.9314 - aux1_accuracy: 0.9469 - aux2_accuracy: 0.9393"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 28s 333ms/step - loss: 0.3094 - main_loss: 0.2066 - aux1_loss: 0.1538 - aux2_loss: 0.1889 - main_accuracy: 0.9314 - aux1_accuracy: 0.9469 - aux2_accuracy: 0.9393\n",
            "Epoch 23/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.3166 - main_loss: 0.2140 - aux1_loss: 0.1532 - aux2_loss: 0.1888 - main_accuracy: 0.9299 - aux1_accuracy: 0.9525 - aux2_accuracy: 0.9416"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 28s 334ms/step - loss: 0.3166 - main_loss: 0.2140 - aux1_loss: 0.1532 - aux2_loss: 0.1888 - main_accuracy: 0.9299 - aux1_accuracy: 0.9525 - aux2_accuracy: 0.9416\n",
            "Epoch 24/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.2618 - main_loss: 0.1751 - aux1_loss: 0.1285 - aux2_loss: 0.1603 - main_accuracy: 0.9461 - aux1_accuracy: 0.9559 - aux2_accuracy: 0.9525"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 28s 335ms/step - loss: 0.2618 - main_loss: 0.1751 - aux1_loss: 0.1285 - aux2_loss: 0.1603 - main_accuracy: 0.9461 - aux1_accuracy: 0.9559 - aux2_accuracy: 0.9525\n",
            "Epoch 25/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.2287 - main_loss: 0.1495 - aux1_loss: 0.1260 - aux2_loss: 0.1378 - main_accuracy: 0.9525 - aux1_accuracy: 0.9593 - aux2_accuracy: 0.9548"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 28s 335ms/step - loss: 0.2287 - main_loss: 0.1495 - aux1_loss: 0.1260 - aux2_loss: 0.1378 - main_accuracy: 0.9525 - aux1_accuracy: 0.9593 - aux2_accuracy: 0.9548\n",
            "Epoch 26/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.2245 - main_loss: 0.1444 - aux1_loss: 0.1318 - aux2_loss: 0.1353 - main_accuracy: 0.9506 - aux1_accuracy: 0.9559 - aux2_accuracy: 0.9525"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 29s 347ms/step - loss: 0.2245 - main_loss: 0.1444 - aux1_loss: 0.1318 - aux2_loss: 0.1353 - main_accuracy: 0.9506 - aux1_accuracy: 0.9559 - aux2_accuracy: 0.9525\n",
            "Epoch 27/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.2263 - main_loss: 0.1541 - aux1_loss: 0.1133 - aux2_loss: 0.1273 - main_accuracy: 0.9457 - aux1_accuracy: 0.9635 - aux2_accuracy: 0.9570"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 28s 334ms/step - loss: 0.2263 - main_loss: 0.1541 - aux1_loss: 0.1133 - aux2_loss: 0.1273 - main_accuracy: 0.9457 - aux1_accuracy: 0.9635 - aux2_accuracy: 0.9570\n",
            "Epoch 28/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.2117 - main_loss: 0.1394 - aux1_loss: 0.1101 - aux2_loss: 0.1309 - main_accuracy: 0.9593 - aux1_accuracy: 0.9638 - aux2_accuracy: 0.9635"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 28s 333ms/step - loss: 0.2117 - main_loss: 0.1394 - aux1_loss: 0.1101 - aux2_loss: 0.1309 - main_accuracy: 0.9593 - aux1_accuracy: 0.9638 - aux2_accuracy: 0.9635\n",
            "Epoch 29/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.2751 - main_loss: 0.1839 - aux1_loss: 0.1399 - aux2_loss: 0.1641 - main_accuracy: 0.9446 - aux1_accuracy: 0.9544 - aux2_accuracy: 0.9514"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83/83 [==============================] - 28s 333ms/step - loss: 0.2751 - main_loss: 0.1839 - aux1_loss: 0.1399 - aux2_loss: 0.1641 - main_accuracy: 0.9446 - aux1_accuracy: 0.9544 - aux2_accuracy: 0.9514\n",
            "Epoch 30/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.2012 - main_loss: 0.1306 - aux1_loss: 0.1133 - aux2_loss: 0.1220 - main_accuracy: 0.9574 - aux1_accuracy: 0.9635 - aux2_accuracy: 0.9627"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83/83 [==============================] - 28s 334ms/step - loss: 0.2012 - main_loss: 0.1306 - aux1_loss: 0.1133 - aux2_loss: 0.1220 - main_accuracy: 0.9574 - aux1_accuracy: 0.9635 - aux2_accuracy: 0.9627\n",
            "338/338 [==============================] - 20s 55ms/step - loss: 2.1450 - main_loss: 1.2651 - aux1_loss: 1.7006 - aux2_loss: 1.2325 - main_accuracy: 0.6662 - aux1_accuracy: 0.6482 - aux2_accuracy: 0.6721\n",
            "validation accuracy [2.1450188159942627, 1.2651028633117676, 1.7005906105041504, 1.2324615716934204, 0.6662178039550781, 0.6482300758361816, 0.6720854043960571]\n"
          ]
        }
      ],
      "source": [
        "googlenet_2 = googlenet()\n",
        "googlenet_2=model_train_generator(googlenet_2,train_iterator,test_iterator,'googlenet_2',30,lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0RzkuvRvQ9Z"
      },
      "source": [
        "\n",
        "\n",
        "> Save best model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcS4LZWblzvn"
      },
      "outputs": [],
      "source": [
        "#Xception.save_weights(\"/content/drive/MyDrive/NNproject/Xception2_weight.h5\")\n",
        "# model_json = Xception.to_json()\n",
        "# with open(\"/content/drive/MyDrive/NNproject/Xception_model.json\",\"w\") as json_file:\n",
        "#   json_file.write(model_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqu76QnwmwUT"
      },
      "source": [
        "<a name='6'></a>\n",
        "# Test CNN models\n",
        "note this is test script that i put it in seperate notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSytaFdym5Xb"
      },
      "outputs": [],
      "source": [
        "from keras.models import model_from_json\n",
        "def predict_(image_path):\n",
        "    image_name=[]\n",
        "    label=[]\n",
        "    #Load the Model from Json File\n",
        "    json_file = open(\"/content/drive/MyDrive/NNproject/Xception_model.json\", 'r')\n",
        "    model_json_c = json_file.read()\n",
        "    json_file.close()\n",
        "    model_c = model_from_json(model_json_c)\n",
        "    #Load the weights\n",
        "    model_c.load_weights(\"/content/drive/MyDrive/NNproject/Xception2_weight.h5\")\n",
        "    #Compile the model\n",
        "    model_c.compile(loss=\"categorical_crossentropy\", optimizer='adam',metrics=[\"accuracy\"])\n",
        "    #load the image you want to classify\n",
        "    i=0\n",
        "    for dirname, _, filenames in os.walk(image_path):\n",
        "        for filename in filenames:\n",
        "            path = os.path.join(dirname, filename)\n",
        "            image = cv2.imread(path)\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            image = cv2.resize(image, (229,229)) \n",
        "            image=image/255.\n",
        "            image-=0.5\n",
        "            image*=2\n",
        "            #plt.imshow(image)\n",
        "           #predict the image\n",
        "            preds = model_c.predict(np.expand_dims(image, axis=0))[0]\n",
        "            res=preds.argmax()\n",
        "            #print(preds)\n",
        "            image_name.append(filename)\n",
        "            label.append(res)\n",
        "            #print(res)\n",
        "            i+=1\n",
        "            # if i==5:\n",
        "            #    break\n",
        "    return image_name, label "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bBRJ6PjnjvJ"
      },
      "outputs": [],
      "source": [
        "img_name,labels=predict_(Test_path)\n",
        "df=pd.DataFrame({'image_name':img_name,'label':labels})\n",
        "\n",
        "df.to_csv('/content/drive/MyDrive/NNproject/Xception.csv', index=False)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1ne8r9bn7xN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}